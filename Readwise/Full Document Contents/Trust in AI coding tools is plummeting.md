# Trust in AI coding tools is plummeting

![rw-book-cover](https://leaddev.com/wp-content/uploads/2025/04/mandate-brink-02.jpg)

## Metadata
- Author: [[Chris Stokel-Walker]]
- Full Title: Trust in AI coding tools is plummeting
- Category: #articles
- Summary: Trust in AI coding tools is dropping as developers find their outputs less accurate and useful. More developers use AI, but they are more careful and rely on human checks to avoid mistakes. Despite doubts, many still see AI as helpful for improving productivity when used wisely.
- URL: https://share.google/UWr2csYokdIBMAzZZ

## Full Document
[![AI coding mandates are pushing developers to the brink](https://res.cloudinary.com/leaddev/image/upload/f_auto/q_auto/dpr_auto/c_limit,h_1536,w_1536/next/2025/04/mandate-brink-02.jpg)](https://leaddev.com/technical-direction/trust-in-ai-coding-tools-is-plummeting)[AI coding mandates are pushing developers to the brink](https://leaddev.com/technical-direction/trust-in-ai-coding-tools-is-plummeting)
A new Stack Overflow survey highlights a steep decline in trust and reliance on AI coding tools, as users get more discerning.

Stack Overflow’s [annual survey of nearly 50,000 developers](https://survey.stackoverflow.co/2025) acts as a useful benchmark of how software engineers are feeling, and this year’s results suggest a steep decline in sentiment around [AI coding tools](https://leaddev.com/velocity/generative-ai-programming-tools-developers).

This year, 33% of developers said they trust the accuracy of the outputs they receive from AI tools, down from 43% in 2024. At the same time, how favourably developers think of adding AI tools into their workflow fell steeply, from 72% in 2024 to 60% this year.

The 10-plus percentage point swing in both questions was something that stood out to the team behind the survey, too. “One of the most notable trends in this year’s survey is the continued rise in AI tool usage – now at 84% of developers using or planning to use them – contrasted with a clear drop in favourability,” says Erin Yepis, senior analyst for market research and insights at [Stack Overflow](https://leaddev.com/technical-direction/how-stack-overflow-innovating-keep-ai-disruption).

#### What’s behind the shift?

Yepis says there are “likely a few forces at play here.” She points out that there was a [gap between the perception of satisfaction](https://leaddev.com/velocity/ai-doesnt-make-devs-as-productive-as-they-think-study-finds) between simple, everyday tasks that devs might do often, and those that they don’t.

“When AI is used for general tasks by those that know what they are looking for, there is not only less room to increase satisfaction, but those tools immediately create a poor experience, too,” she says.

The underwhelming performance of AI at things developers already know how to do is just one indication of why there has been a shift in sentiment. “Developer trust in AI is becoming more realistic as the industry moves beyond the initial hype phase. With increased experience, developers now have a better understanding of AI’s capabilities and limitations,” says Raj Kesarapalli, director at application security company Black Duck.

Kesarapalli says that we might be at that inflection point where developers are starting to utilize AI tools more judiciously, and are similarly considering the way they perform when set to the tasks they’re given. “Ultimately, effective use of AI depends on understanding its strengths and weaknesses and knowing when and how to leverage it,” he says.

#### Hype versus reality

The reality of performance versus hype is why Andrey Korchak, a longtime former chief technology officer, believes we are seeing plummeting trust figures in Stack Overflow’s survey.

“One of the most common stories I hear in 2025 goes like this: someone gives an AI coding agent a try, expecting magic,” he says. “But after a few actions, it messes up the architecture, changes something it shouldn’t, or just spits out bad code.”

At that point, Korchak says, many people might step away from AI, without realizing that the time invested can pay dividends through better prompts or more reasonable expectations.

The answer, for now, is more human oversight of AI outputs to understand *why* AI tools are failing to carry out user requests as intended. Three in four developers who responded to Stack Overflow’s survey say they’ll revert to human oversight when they don’t trust an AI-generated answer.

But there is still a silver lining, says Yepis. “It’s not that developers are abandoning AI – usage is growing, and 69% of the developers using [AI agents](https://leaddev.com/technical-direction/why-everyones-suddenly-talking-about-ai-agents) at work agree that productivity is improving,” she says.

Instead, the stats show that developers are using AI more judiciously. “They’re learning [where AI fits in their workflows](https://leaddev.com/velocity/writing-code-was-never-the-bottleneck) – and where it doesn’t,” she says. “That’s a natural progression as a new technology matures: initial enthusiasm gives way to realism, and we’re seeing that shift play out in this year’s results.”
