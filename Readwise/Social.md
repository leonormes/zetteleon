# Social

![rw-book-cover](https://images-na.ssl-images-amazon.com/images/I/41ydHdEAlRL._SL200_.jpg)

## Metadata
- Author: [[Matthew D. Lieberman]]
- Full Title: Social
- Category: #books

## Highlights
- We have already discussed at length the reasons why mammals, and particularly humans, need to feel social separation as painful. It keeps infants and caregivers close together. That may have been the reason evolution gave us social pain, but now we are stuck with it our entire lives, and it colors almost every social experience we have. ([Location 958](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=958))
- Evolution built us to desire and work to secure positive social regard. Why are we built this way? One possible explanation is that when humans, or other mammals, get together, work together, and care for one another, everyone wins. Given that other living creatures are the most complex and potentially dangerous things in our environment, a push from nature to connect with others in our species, an urge to please one another, increases our chances of reaping the benefits of group-based living. ([Location 1130](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1130))
    - Tags: [[team]] [[favorite]] 
- Cooperation is one of the things that makes humans special. Many species cooperate, but as Melis and Semmann write, no other species comes close “to the scale and range of [human] cooperative activities.” Compared to the rest of the animal kingdom, humans are supercooperators. ([Location 1140](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1140))
- If you want to make the most money and you assume the other person will cooperate, you should defect (because you’ll earn $10 instead of $5). If you assume the other person will defect, then you should still defect (because you’ll earn $1 instead of nothing). Regardless of what the other person does, you make more money by defecting. Nevertheless, multiple studies have shown that under these conditions, people still choose to cooperate more than a third of the time. ([Location 1163](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1163))
- The eighteenth-century philosopher David Hume proposed that political systems should be based on the assumption that a man has “no other end, in all his actions, than his private self-interest.” ([Location 1171](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1171))
- A century earlier, the philosopher Thomas Hobbes first formalized this account, charging that “every man is presumed to seek what is good for himself naturally, and what is just, … accidentally.” This basic assumption is known as the axiom of self-interest. ([Location 1173](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1173))
- In some variants of the Prisoner’s Dilemma, Player A is informed of Player B’s decision before making his own. Not surprisingly, when Player A is told that Player B has chosen to defect, Player A always decides to defect (assuring himself of $1 instead of $0). What is surprising, though, is that when Player A is told that Player B has chosen to cooperate, Player A increases his own rate of cooperation from 36 to 61 percent. Player A is willfully choosing to earn $5 instead of $10, when the supposedly rational thing to do would be to defect. ([Location 1177](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1177))
- The only reasonable explanation is that in addition to being self-interested, we are also interested in the welfare of others as an end in itself. This, along with self-interest, is part of our basic wiring. ([Location 1185](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1185))
- In fact, the individuals in Rilling’s study showed the opposite pattern. When the participants’ partners chose to cooperate, more ventral striatum activity was observed in players when they too had chosen to cooperate, rather than defect. In other words, there was increased reward activity even though the players were earning less money for themselves. The ventral striatum seemed to be more sensitive to the total amount earned by both players, rather than to one’s personal outcome. Moreover, the lateral prefrontal regions were not engaged in the study when subjects cooperated, suggesting that cooperating involves a real preference, not a sense of obligation. ([Location 1206](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1206))
- But Rilling published another study a few years later in which only a single game was played with each partner, ruling out long-term strategies like reputation building. Nevertheless, he got the same results—mutual cooperation produced the greatest activity in the ventral striatum. ([Location 1212](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1212))
- Mutual cooperation activates the reward system as an end in itself. ([Location 1219](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1219))
- “on closer inspection, … acts of apparent altruism are really selfishness in disguise.” Perhaps the person who receives help will reciprocate directly. Or the person offering help will be seen in a more beneficial way in the eyes of others, allowing him or her to gain more later. We all wonder at times what people hope to gain from their seemingly altruistic behavior. ([Location 1228](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1228))
- Psychologist Daniel Batson showed that there may be a hidden selfish motivation at work in John’s willingness to switch, just like the protagonist in Asimov’s story. Batson conducted ingenious studies in which one person (the observer) had to watch another person (the victim) receive painful shocks. The victim was clearly very bothered by the shocks and at one point asked if the shocks could be stopped. The experimenter then asked the observer if he would take the victim’s place and receive the remainder of the shocks. Some observers were given the choice of either switching places or continuing to watch the victim receive shocks. Other observers were given the choice of either switching places or going home (without watching any more of the shocks). Those who would have to stay and continue to watch were much more likely to switch places with the victim than were those who could go home if they declined to switch places. In other words, if it is easy to escape the unpleasant situation, people do, but if it is hard, people decide that doing “the right thing” is better than having to watch the other person endure the shocks. Their willingness to let the victim continue to receive shocks, as long as they won’t have to watch it happen, revealed that their motive was not purely altruistic. ([Location 1234](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1234))
- As the Dalai Lama advises, “If you would like to be selfish, you should do it in a very intelligent way. The stupid way to be selfish is the way we always have worked, seeking happiness for ourselves alone and in the process becoming more and more miserable. The intelligent way to be selfish is to work for the welfare of others” because doing so is intrinsically pleasurable. ([Location 1266](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1266))
- The Prisoner’s Dilemma studies were the first to demonstrate that the brain’s reward system responds to valuing the outcomes of others, in addition to one’s own. One could argue that the study did not go far enough to prove the case, because when participants chose to cooperate, they were still getting paid, just not as much as they would have received if they had defected. But a more recent study provides even more compelling evidence that our reward system is sensitive to the welfare of others. ([Location 1269](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1269))
- Jorge Moll and his colleagues at the National Institutes of Health ran an fMRI study looking at the activity in the brain when we’re giving to charity. Individuals in the scanner were asked to make a series of decisions that involved financial outcomes for themselves and for a charitable organization (different decisions involved different charities). On some trials, individuals were asked whether they would agree to receive $5 for themselves with no consequences for any charity. Not surprisingly, individuals were very quick to accept this kind of reward. On other trials, individuals were asked if they were willing to give up some of their winnings (for example, lose $2) so that a charity would receive $5. Amazingly, as a group, the individuals in this study showed even greater activity throughout the reward regions of the brain when they made the choice to give away some of their own money to help others, compared to when they received money with no strings attached. Our supposedly selfish reward system seems to like giving more than receiving. ([Location 1272](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1272))
- Eva Telzer, Andrew Fuligni, and I replicated this finding with what you might expect to be some of the most selfish people on the planet: teenagers. Instead of mentioning a charity, we asked teenagers to make costly donations to their own families. We told the teenagers, as well as their parents, that as a precondition of being in the study, any money given to the family must not be spent on the teenager who donated it. The majority of these teenagers reported taking pleasure in helping their families in daily life; they also showed increased reward system activity when donating their money to their families. ([Location 1280](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1280))
- On these trials, providing support through physical contact when the girlfriends knew their boyfriends were likely distressed was more rewarding than touching their boyfriends when no support was needed. Providing social support, even when doing so puts us in closer contact with someone else’s distress, is reinforced in our brains. ([Location 1290](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1290))
#### Why Are Social Rewards Rewarding?
- As we’ve seen, there are two kinds of social rewards—the social rewards we receive when others let us know they like, respect, or care for us and the social rewards we receive when we care for or treat others well. ([Location 1307](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1307))
- It is no accident that this parallels the two sides of the mother-infant relationship. Having strangers tell us they like us is pleasurable, in part, because we humans have generalized the positive feelings of being cared for by our mothers. Many mammalian species have shown opioid-linked pleasure responses in the brain while being groomed by their mother or peers. But in humans most of our grooming is verbal rather than physical. When others spend time verbally grooming us, it is a sign that we are safe and cared for. And given our long period of immaturity, this is an incredibly reinforcing signal to receive. ([Location 1308](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1308))
- Mammals are thus in a bit of a bind because, on the one hand, their offspring are strangers that we are built to avoid, and on the other hand, caring for our young is essential for their survival. Oxytocin appears to alter the dopaminergic response of mammals to their own infants, tipping the balance from avoidance to approach. ([Location 1328](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1328))
- Oxytocin in humans helps to promote altruistic tendencies not toward one’s own group—because that isn’t altruism in the strongest sense of the word—and not toward members of disliked groups. But oxytocin can increase our generosity toward complete strangers, which is quite magical, as strangers who start with a positive bias toward one another can do great things together, such as building houses, schools, and other institutions that support a society. ([Location 1360](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1360))
- Miller has shown in multiple experiments that we assume others are far more self-interested than they really are. In one study, he asked individuals what percentage of undergraduates they thought would agree to give blood for $15 and what percentage would agree to give blood if there were no financial incentive. Respondents estimated half as many people would give blood for free as would for the money (32 versus 62 percent). But in measuring actual volunteer rates, he found that those who were offered no money agreed to give blood 62 percent of the time, only slightly less often than those who were paid (73 percent). ([Location 1381](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1381))
- The irony of this was brought home in another of Miller’s studies. People were approached to donate to a charity. People who were asked to simply donate found it hard to generate a self-interested explanation for helping the charity. Other people were informed that they would receive a small candle in return for their donation. The candle created an exchange fiction, allowing people to say, “I didn’t donate to help. I was buying a candle.” As expected, people were more likely to donate when they would get a candle in return compared to when no candle was offered. They also donated much more money under these conditions. Ironically, getting a trinket in return allows us to cover our generosity with a nonaltruistic account and thus frees us to act more altruistically. ([Location 1392](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1392))
- and unselfish motives. And this is no accident. Mammalian brains are wired to care for others, and among primates this caring extends to at least some non-kin, even when there is no material return on the investment. Because of the way our brains are wired, eating a delicious piece of cake is enjoyable whether we are hungry or not. Similarly, helping others feels good whether we expect something in return or not. ([Location 1403](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1403))
- Over time we develop a very complex theory of how different situations and outcomes are likely to affect a typical person’s thinking and how that person will subsequently behave. If ([Location 1558](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1558))
- Logical reasoning comes in two flavors: deductive and inductive. ([Location 1568](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1568))
- In deductive reasoning, we assess what must be the case if a set of premises is assumed to be true. Consider the following premises: 1. If it rains, then the picnic will be canceled. 2. It is raining. If those two premises are true, then we must logically conclude the picnic has been canceled. This is an example of deductive reasoning, and this kind of if-then reasoning is central to our prodigious problem-solving abilities. ([Location 1569](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1569))
- More generally, these lateral frontoparietal regions support countless kinds of effortful thinking through a process known as working memory. Working memory is the psychological process commonly associated with mentally holding and updating multiple pieces of information. ([Location 1585](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1585))
- People who can hold more information in mind and reason about that information effectively are seen as more intelligent than others who cannot. ([Location 1598](https://readwise.io/to_kindle?action=open&asin=B00FWPOOUU&location=1598))
