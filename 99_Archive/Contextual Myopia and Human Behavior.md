---
aliases: [Limits of Human Cognition, Myopic Understanding, The Hill Analogy]
confidence: 5/5
confidence-gaps: []
created: 2025-12-11T00:00:00Z
decay-signals: []
epistemic:
last-synthesis: 2025-12-11
last_reviewed: 2025-12-11
modified: 2025-12-11T20:18:55Z
purpose: To define the inherent limitations of human cognitive processing and the role of abstraction as a compensatory mechanism.
quality-markers: [Connects abstraction to prediction., Explains the hill climbing analogy., Integrates predictive processing concepts.]
related-soTs: ["[[Mental Models MOC]]", "[[MOC - Cognitive Abstraction and Understanding]]", "[[SoT - PRODOS (System Architecture)]]"]
resonance-score: 8
review_interval: 6 months
see_also: []
source_of_truth: true
status: stable
supersedes: ["[[Human Understanding is Inherently Myopic]]", "[[Myopic understanding]]"]
tags: [abstraction, cognition, mental_models, psychology, understanding]
title: SoT - Myopic Understanding
type: SoT
uid:
updated:
---

## 1. Definitive Statement

> [!definition] Definition
> **Myopic Understanding** describes the fundamental cognitive constraint where human processing power is insufficient to grasp the full complexity of reality simultaneously. To compensate, the brain utilizes **abstraction**, trading high-fidelity details (Depth) for broader context (Breadth).
>
> Understanding is not a static state of "knowing," but a dynamic capacity to make **accurate predictions** about cause-and-effect relationships within a specific scope.

---

## 2. The Core Problem: The Bandwidth Bottleneck

Humans exist in a high-complexity reality but possess a low-bandwidth cognitive processor.

-   **The Constraint:** [[Limited Human Information Processing Capacity]]. We can only hold a few variables in working memory at once.
-   **The Consequence:** We are effectively "blind" to the majority of system dynamics at any given moment. We see the tree, but miss the forest; or we see the forest, but miss the tree.
-   **The Necessity of Models:** Because we cannot process raw reality, we must rely on simplified internal representations—[[Mental Models]]—to function.

---

## 3. Current Understanding: The Hill Analogy

The primary mechanism for overcoming cognitive myopia is **Abstraction**.

### The "Hill Climbing" Model

Imagine understanding as standing on a landscape.

1.  **Low Abstraction (The Valley):** You are on the ground. You can see the grass, the bugs, and the dirt in high definition (High Resolution). However, you cannot see where the path leads or what is over the next ridge (Low Context/Prediction).
2.  **High Abstraction (The Summit):** You climb the hill. Now you can see the entire valley, the river's path, and the weather approaching (High Context/Prediction). However, you can no longer distinguish individual blades of grass (Low Resolution).

> **Key Insight:** You cannot be on the mountain and in the valley simultaneously. **All understanding involves a trade-off between Breadth (Context) and Depth (Detail).**

### The Purpose of Understanding

Evolutionarily, the brain is a [[The Brain as a Distributed Prediction Machine|prediction machine]].

-   **Prediction:** The goal of "understanding" is to minimize [[Prediction Error Drives Dopamine Release|prediction error]].
-   **Causality:** A wider view (higher abstraction) allows us to see longer chains of cause-and-effect ("If I do X, Y will happen").
-   **Myopia's Cost:** When our view is too narrow (myopic), we fail to predict second-order consequences, leading to errors in judgment.

---

## 4. Minimum Viable Understanding (MVU)

1.  **Humans are functionally myopic:** We perceive a sliver of reality.
2.  **Abstraction is Altitude:** We climb the "ladder of abstraction" to see further and predict better.
3.  **Context requires Compression:** To see the big picture, we must ignore the details.
4.  **Understanding = Prediction:** The measure of understanding is not facts, but the ability to accurately predict outcomes.

---

## 5. Tensions & Gaps

-   **The Map vs. Territory Problem:** High abstraction creates an [[Illusion of Explanatory Depth (IoED)]]. We think we understand the system because we see the high-level shape, but we fail when granular details matter (e.g., a CEO understanding "strategy" but failing at "execution").
-   **Salience Bias:** Our mental models are not neutral maps; they are filtered by [[Salience Determines What Information Enters Mental Models|salience]]. We see what we value or fear, not necessarily what is objectively most important.
-   **Dynamic Loss:** Moving up the abstraction ladder is "lossy" compression. Critical signals can be lost in the smoothing process.

---

## 6. Related Components
-   [[SoT - Contextual Myopia and Self-Referential Meaning]]
-   [[Abstraction Improves Breadth of Understanding]]
-   [[Understanding Enables Accurate Predictions]]
-   [[Understanding Reveals Cause-and-Effect]]
-   [[Predictive Processing and the Bayesian Brain]]
-   [[Mental Models MOC]]
