---
aliases: []
confidence: 
created: 2025-08-26T09:27:12Z
epistemic: 
last_reviewed: 
modified: 2025-10-30T10:27:46Z
purpose: 
review_interval: 
see_also: []
source_of_truth: []
status: 
tags: [information]
title: Kolmogorov Complexity - Information as Compressibility
type:
uid: 
updated: 
version:
---

An alternative mathematical framework that aligns more closely with the intuitive idea of [[Information as Perceivable Pattern]] is Algorithmic Information Theory, specifically Kolmogorov Complexity.

- Definition: The Kolmogorov complexity of an object (like a string of text) is the length of the shortest computer program that can produce it as output.

This defines information in terms of compressibility:

- Low Complexity (Patterned Data): A string with patterns, rules, and repetition (e.g., `abababab...`) can be generated by a very short program ("print 'ab' 4 times"). It is highly compressible and has low Kolmogorov complexity.
- High Complexity (Random Data): A truly random string has no shorter description than the string itself. It is incompressible and has high Kolmogorov complexity.

In this view, "information" as a usable pattern corresponds to low Kolmogorov complexity. Pure noise is unstructured and therefore not "informative" in a descriptive sense.

- Links: [[Information as Perceivable Pattern]], [[The Conflict Between Semantic and Shannon Information]], [[Shannon's Information Theory - Information as Uncertainty]]
