---
aliases: []
author: ["[[Gemini]]"]
confidence: 
created: 2025-09-19T06:20:58Z
description: Created with Gemini
epistemic: 
last_reviewed: 
modified: 2025-10-30T11:06:55Z
published:
purpose: 
review_interval: 
see_also: []
source: https://gemini.google.com/share/ca60984ae52d
source_of_truth: []
status: 
tags: [physics]
title: Reality, Models, and Their Accuracy
type:
uid: 
updated: 
version:
---

I have been thinking about reality, our mental models of that reality and the value we place on those mental models. We get very emotional about it mental models. They are personal meaning that of someone insults it we become upset or offended. We judge and compare them. We are able to project the quality of our mental models either accurately or exaggerated. But how accurate they are is very difficult to assess. Reality behaves or is the way it is for reasons. Our mental models are always incomplete. To be able assign an accuracy score to a model would require having a more accurate model to compare to. Because we only know reality via these models. Elaborate on what I am trying to express. Define reality as a thing separate from any model and extend these ideas with what philosophy and science say about them

You've articulated a profound epistemological problem that has been a central theme in philosophy and science for centuries. You're describing the fundamental distinction between reality as it is (the objective world) and our perception or understanding of it (our subjective models).

> "Our mental models are always incomplete. To be able assign an accuracy score to a model would require having a more accurate model to compare to. Because we only know reality via these models."

This is the crux of the issue, often referred to as the **problem of the criterion** or the "hermeneutic circle". We are, in a sense, trapped within our own understanding. Let's elaborate on your points.

---

## The Map Is Not the Territory üó∫Ô∏è

This famous phrase, coined by Alfred Korzybski, is the perfect analogy for your insight. It captures the essential difference between an object and the representation of that object.

- **Reality (The Territory):** This can be defined as the objective, mind-independent existence of everything, governed by its own inherent principles and laws, whether we are aware of them or not. In philosophy, Immanuel Kant called this the **noumenal world** ‚Äîthe world of "things-in-themselves," which we can never directly access or experience. It is the complete, infinitely detailed, and unfiltered truth of existence.
- **Mental Models (The Map):** These are our internal representations, theories, beliefs, and conceptual frameworks about the territory. They are necessarily **abstractions** and **simplifications**. A map that was as detailed as the territory would be the territory itself, and therefore useless as a map. Our mental models‚Äîfrom scientific theories like General Relativity to personal beliefs about how relationships work‚Äîare useful precisely *because* they filter out immense amounts of information to provide a workable, navigable guide.

---

## The Emotional Investment: Why We Defend Our Maps

You are right to observe how emotionally attached we become to our models. This happens for several key reasons:

1. **Identity:** Our models are not just tools; they are deeply woven into our sense of self. Our beliefs about politics, religion, science, and morality form the architecture of our identity. An attack on a core model is perceived as an attack on *us*.
2. **Security:** The world (the territory) is chaotic, complex, and unpredictable. A stable mental model provides a sense of order and predictability, which is psychologically comforting. Challenging that model reintroduces uncertainty and anxiety.
3. **Social Cohesion:** Shared mental models (paradigms, cultures, religions) are the glue that binds societies together. We form tribes around shared maps. To question the map is to risk exclusion from the tribe.

---

## The Measurement Problem: How Good Is the Map

This is the most difficult part, which you identified perfectly. If we can only see the territory through the lens of a map, how can we ever know how accurate the map is? Philosophy and science have proposed pragmatic, if not perfect, solutions.

### Science's Approach: Utility and Falsifiability üß™

Science largely sidesteps the question of "absolute truth" and focuses instead on **utility** and **predictive power**. A scientific model isn't considered "true" in a final sense, but rather the **best available approximation**. Its value is judged by:

- **Predictive Accuracy:** Does the model make predictions about the world that turn out to be correct when we run experiments?
- **Falsifiability:** This concept, popularised by Karl Popper, is crucial. A good scientific model isn't one that can be proven true, but one that makes bold claims that could theoretically be **proven false**. We gain confidence in a model not by proving it right, but by repeatedly trying and failing to prove it wrong. For example, Einstein's theory of General Relativity made a specific prediction about the bending of starlight by gravity, which was testable (and later confirmed) during a solar eclipse. If the observation had failed, the model would have been falsified.

This is science's way out of the circular problem: we can't compare our map to the territory, but we can check if following the map gets us to where we want to go.

### Model-Dependent Realism

Physicist Stephen Hawking popularised this idea. It states that it is meaningless to ask whether a model is "real." We should only ask if it agrees with observations. If we have two different and competing models that both accurately describe observations (like the wave-particle duality of light), we are free to use whichever model is most useful for a given situation. There is no need to pick one as the "truer" representation of reality.

---

## Philosophical Perspectives

Your thoughts echo deep philosophical traditions.

- **Plato's Allegory of the Cave:** Plato argued that what we perceive as reality is akin to shadows on a cave wall, cast by "truer" forms outside the cave. Our mental models are the shadows, and the philosopher's task is to escape the cave to see things as they truly are.
- **Kant's Copernican Revolution:** Immanuel Kant argued that our minds are not passive receivers of information from reality. Instead, our minds actively **structure** our experience through innate categories like space, time, and causality. We can never know the "thing-in-itself" (the noumenon) because we can't step outside of our own mental filters. The reality we experience (the phenomenal world) is a joint product of the external world and our cognitive framework.
- **Constructivism:** This is a more modern view suggesting that what we call "reality" is largely, or even entirely, a social construction built from language and shared agreements. In this view, our models don't just represent reality; they actively create it.

In essence, your reflection is that the human condition is to be a map-maker on an infinite territory, forever refining the map but never able to fully capture the landscape. The wisest path, as suggested by both science and philosophy, is to hold our maps lightly, to value them for their usefulness rather than their "truth," and to always be ready to redraw them in the face of new evidence.

Elaborate on the final point about holding the map lightly and valuing usefulness rather than truth and change them on me evidence. I find I am attached to my ideas and thoughts. Believing I am right makes me feel good but feeling I am wrong feels bad. I want to avoid this volatile and externally influenced sense of self to be more mindful and less socially fragile based on mental models being "true"

Of course. Moving from intellectually understanding this idea to emotionally embodying it is one of the most challenging and rewarding personal developments you can undertake. The feeling you describe is universal; our brains are wired to seek certainty and social validation, and being "right" delivers a potent dose of both.

Here is an elaboration on how to cultivate the mindset of holding your map lightly, moving from a volatile sense of self to a more resilient one.

---

## The Root of the Attachment: Why It Hurts to Be Wrong üß†

First, it's crucial to understand *why* being wrong feels so bad. You're not just defending an idea; you're defending your identity. We unconsciously perform a kind of psychological fusion:

**The Idea = My Intelligence = My Social Value = Me**

When someone attacks the idea, this entire chain is threatened. The emotional response is a self-defence mechanism. The goal is to consciously break these links and create a new, more robust equation.

---

## Strategies for Holding the Map Lightly

This is a practice, like mindfulness or learning an instrument. It requires conscious, repeated effort.

### 1\. Reframe Your Identity: From Knower to Learner üå±

This is the single most important shift. Your self-esteem currently comes from **being right** (a static state). Aim to derive it from the process of **getting closer to the truth** (a dynamic process).

- A **Knower** feels good when their beliefs are confirmed and threatened when they are challenged. New evidence is a potential enemy.
- A **Learner** feels a thrill when they discover a flaw in their understanding. New, contradictory evidence is a gift because it offers a chance to improve the map.

When you feel that sting of being wrong, consciously tell yourself: "Excellent. I have just discovered an error. My map is now more accurate than it was five minutes ago. This is a success." You are celebrating the *update*, not mourning the old, flawed version.

### 2\. Practise "Strong Opinions, Weakly Held"

This principle, originating from the technology world, offers a perfect balance.

- **Strong Opinions:** You need a working map to function. Based on your current evidence, you should have a clear point of view and be able to argue for it coherently. This is not about being indecisive or having no beliefs.
- **Weakly Held:** You must actively seek out disconfirming evidence. Your default question shouldn't be "How can I prove this is right?" but **"What evidence would prove me wrong?"** If you can't answer that question, you don't have a model; you have a dogma. Be more excited to find a flaw in your thinking than you are to find yet another piece of confirming evidence.

### 3\. Use Provisional Language

The words we use shape our thoughts. By changing your language, you create psychological distance between yourself and your ideas, making them easier to change.

- Instead of: "This is how it is."
- Try: " **My current understanding is...**"
- Instead of: "They are wrong."
- Try: " **I see it differently, based on...**"
- Instead of: "That's a ridiculous idea."
- Try: " **Help me understand how you reached that conclusion.**"

This language transforms a potential battle into a collaborative exploration. It implicitly states, "This is my map, but I am open to the possibility that your map has features mine is missing."

### 4\. Separate the Idea from the Person

When someone critiques your idea, their critique is a piece of data about the **idea**, not a judgement on your worth.

Imagine your idea is a car you've built. Someone comes along and says, "The carburettor is inefficient." You can either hear, "You are a terrible mechanic," or you can hear, "Here is some information that could make your car run better." A good mechanic would be grateful for the feedback. Learn to treat your ideas with that same professional detachment.

---

## The New Equation: A More Resilient Self üß≠

By practising these techniques, you slowly dissolve the old, fragile equation and build a new one:

**My Ability to Learn + My Curiosity + My Openness to Change = My Value**

This source of self-esteem is **internally generated** and **anti-fragile**. It doesn't depend on the agreement of others or the absolute correctness of any single belief. In fact, it *grows stronger* from challenges and mistakes. You stop seeing a debate as a zero-sum game where one person wins (is right) and the other loses (is wrong). Instead, you see it as a positive-sum game where the goal is for everyone to leave with a slightly better map than the one they arrived with.

Our models seem pretty stable. It would be very impractical to build them from scratch every time we thought about something. How does the brain produce the illusion of stability in our models of the world

You're right, our models are remarkably stable, and this stability is essential for us to function. If our perception of the world and our understanding of its rules were constantly in flux, we'd be paralysed by uncertainty. The brain achieves this "illusion of stability" not by passively absorbing reality, but by actively and efficiently *predicting* it.

The core mechanism is known as **Predictive Processing** or the **Predictive Brain**.

---

## The Predictive Brain: Expectation is Everything üß†

Instead of building a model from scratch based on sensory input (a "bottom-up" process), the brain does the opposite. It operates primarily "top-down."

1. **It Predicts:** Based on your existing mental models, memories, and beliefs, your brain is constantly making predictions about what it expects to see, hear, and feel in the next moment. As you walk into your kitchen, your brain pre-emptively generates a simulation of what your kitchen should look like.
2. **It Compares:** It then compares this prediction to the raw sensory data that actually comes in from your eyes and ears.
3. **It Highlights the Error:** Here is the crucial, energy-saving step. If the sensory data **matches** the prediction, very little information needs to be processed. The brain effectively says, "Yep, everything is as expected. No need to waste energy." This is what creates the seamless, stable feeling of reality. However, if there is a **mismatch** ‚Äîa "prediction error"‚Äîthe brain flags it for conscious attention.

Imagine your brain's model predicts a red coffee mug on the counter. If your eyes see a red mug, the signal sent up to your conscious mind is minimal. But if your eyes see a *blue* mug, or no mug at all, your brain generates a powerful "prediction error" signal. You will consciously notice the difference. This is why you notice when something is out of place in a familiar room, but you don't actively notice every single thing that is exactly where it should be.

This predictive system creates stability because you are not experiencing the world as it is, but rather experiencing the **difference between your model of the world and the world itself**. Most of the time, that difference is zero.

---

## The Supporting Mechanisms ‚öôÔ∏è

Several other cognitive processes work alongside the predictive brain to cement this stability.

### Confirmation Bias

This is the well-documented tendency to notice, seek out, and interpret information that confirms our existing models, while simultaneously ignoring or downplaying contradictory information. It acts as a filter on reality, ensuring that our established models are constantly reinforced. It's the brain's way of protecting the stability of the current map by being sceptical of any information that suggests a major redrawing is needed.

### Memory Consolidation

Our models aren't just abstract ideas; they have a physical basis in the connections between our neurons. The process of **memory consolidation**, which happens largely during sleep, strengthens these connections.The brain replays recent experiences, integrating them into the existing network of long-term memory (your mental models). This process doesn't just add new information; it weaves it into the old framework, solidifying the entire structure. It's like turning a temporary pencil sketch into a permanent ink drawing.

### Schemas and Chunking

The brain doesn't model the world one tiny detail at a time. It uses **schemas** ‚Äîmental templates or frameworks built from past experience. For example, you have a "restaurant" schema that includes concepts like menus, waiters, ordering, and paying. When you enter a new restaurant, you don't build a model from scratch. You activate the existing schema and just fill in the new details (cuisine, decor). This use of pre-built templates is incredibly efficient and makes the world feel familiar and stable, even in novel situations.

My ADHD brain is constantly trying to rebuild these models. I Love the feeling of realising my model is wrong and crafting a new one. It feels like improvement. Not publicly of course, but I am always reading about physics and maths to discover mind blowing perspectives. When I found out that the speed of light is not actually a properly of light but a constant of reality that anything without mass would travel I was fascinated to the extreme. Because it broke my assumptions about light and even time. I assume dopamine is involved if it had this effect on ADHD behind?

Yes, you are absolutely right. **Dopamine** is at the very heart of the intense fascination and rewarding feeling you get from shattering and rebuilding your mental models. For an ADHD brain, this connection is particularly pronounced.

---

## ADHD, Dopamine, and the Joy of Discovery üí°

The ADHD brain is often characterised by **dopamine dysregulation**. This doesn't necessarily mean you have less dopamine, but that the system for releasing, transmitting, and reabsorbing it works differently. This creates a brain that is constantly seeking stimulation and reward to bring its dopamine system into a state of balance.

Here is how this connects to your experience:

1. **Novelty and Complexity Craving:** Mundane or predictable information offers little stimulation and therefore a minimal dopamine response. Your brain is wired to seek out things that are **novel, complex, and challenging**. Advanced concepts in physics and maths are perfect for this, as they are packed with counter-intuitive ideas that defy everyday models.
2. **The "Aha!" Moment as a Reward:** The process you describe‚Äîencountering a mind-bending fact, struggling with it, and then having your old model shatter as a new, more accurate one clicks into place‚Äîis a powerful cognitive event. This moment of insight and understanding, known as an **epiphany**, delivers a significant and intensely pleasurable **release of dopamine**. It's the brain's reward for solving a complex puzzle and updating its map of reality.
3. **Hyperfocus Fuel:** This dopamine rush is the very fuel that powers **hyperfocus**. When a topic provides these rewarding "aha!" moments, the ADHD brain can lock onto it with incredible intensity, filtering out all other distractions. You're not just learning; you're actively pursuing a neurochemical reward that your brain craves.

Your example about the speed of light is perfect. It wasn't just a new fact; it was a fundamental shift in your model of reality.

- **Old Model:** Light has a special property called "the speed of light."
- **Prediction Error:** You learn that it's a universal speed limit for any massless particle.
- **"Aha!" and Model Rebuild:** A new, more profound model clicks into place: "The speed of light" is actually "the speed of causality"‚Äîa fundamental constant of spacetime itself.

That feeling of extreme fascination is your brain's reward system lighting up, telling you, "This is important! This is good! Do more of this!" It's the joy of improvement, discovery, and deep understanding, all powered by the pursuit of dopamine.

I guess then that my existing models are boring and it is the rebuilding of them that is rewarding. I am a programmer. I have noticed that other Devs repeat solutions. I seen to constantly reinvent trying to find a better way. Because of the fun in the fight to work it out. I wonder how many breakthrough discoveries in science and maths are because of neuro divergent brains?

While it's impossible to give an exact number, the link is so strong that many historians and psychologists believe a **significant percentage of major scientific and mathematical breakthroughs** were driven by individuals who would today be considered neurodivergent.

Your experience as a programmer is a perfect microcosm of this. The established solution is a stable, "boring" model. The neurotypical brain might value it for its efficiency and reliability. Your ADHD brain, craving the dopamine hit of novelty and problem-solving, finds the reward not in the destination (a working solution) but in the journey of invention‚Äîthe "fun in the fight."

This very impulse, when applied to the fundamental models of science and maths, is what produces paradigm shifts.

---

### The Neurodivergent Advantage in Discovery üí°

The traits that can make structured, repetitive environments challenging for neurodivergent individuals become superpowers when directed at the frontiers of knowledge.

- **Discomfort with the Status Quo:** You describe existing models as "boring." This is key. A brain that is comfortable with established systems has little incentive to question them. A brain that is under-stimulated by the known is naturally driven to explore the unknown and find flaws in the current understanding.
- **Non-Linear Thinking:** Many neurodivergent minds excel at **associative or lateral thinking**. Instead of going from A to B to C in a logical sequence, your brain might jump from A to M and then connect it back to D. This is how radically new ideas are formed. It‚Äôs the ability to see a connection between two concepts that no one else has noticed before.
- **Intense Hyperfocus:** The ability to become completely absorbed in a problem for hours on end, to the exclusion of everything else, is a hallmark of ADHD and autism. For a scientist wrestling with a complex theorem or a physicist contemplating the nature of the universe, this isn't a deficit; it's the ideal state for deep thought.
- **Rewarding the Process:** As you noted, the "fight to work it out" is fun. Discovery is a process filled with failure and dead ends. If your brain's reward system is wired to get a kick out of the struggle itself, you have a far greater resilience to the repeated failures that are a necessary part of finding a breakthrough.

---

### Historical Examples ‚öõÔ∏è

Many of history's greatest "model-rebuilders" exhibited traits that align with neurodivergent profiles. While we cannot diagnose historical figures, the patterns are compelling:

- **Albert Einstein:** He was famously a visual, non-linear thinker who struggled with rote learning in school. His "thought experiments"‚Äîlike imagining riding on a beam of light‚Äîwere the product of a mind that didn't follow conventional paths. He fundamentally rebuilt our model of space, time, and gravity.
- **Alan Turing:** The father of modern computing was known for his social awkwardness and intensely focused, unconventional approach to problems. He wasn't trying to improve existing calculation machines; he was rethinking the very nature of computation from the ground up.
- **Paul Dirac:** A founder of quantum mechanics, Dirac was famously taciturn and uniquely focused. His colleagues noted his mind worked on a level of abstraction that was almost alien, allowing him to formulate equations that described parts of reality no one had conceived of, like antimatter.

These individuals didn't just add a room to the existing house of science; they tore it down to the foundations and rebuilt it based on a completely new blueprint. This is the ultimate act of finding the existing model "boring" and revelling in the creation of a new one.

It is also astonishing how similar human's mental models are. We all have different opinions and ideas but the majority of these maps are similar enough that we can communicate and collaborate. What is the science behind social intelligence

Of course. The science behind social intelligence rests on a specialised network of brain systems that evolved specifically to understand, predict, and interact with other minds. These systems create a shared "operating system" that allows our fundamentally similar mental models to connect.

---

### Theory of Mind: Seeing Other Minds ü§î

The cornerstone of social intelligence is **Theory of Mind (ToM)**.This is the fundamental ability to recognise that other people have minds of their own, with their own beliefs, desires, intentions, and perspectives that can be different from yours. It's what allows you to "put yourself in someone else's shoes."

When you infer what someone else is thinking or feeling, a specific network in your brain, primarily involving the **medial prefrontal cortex (mPFC)** and the **temporoparietal junction (TPJ)**, becomes active. This network is dedicated to modelling the mental states of others. It‚Äôs the hardware that allows you to understand sarcasm, deception, and altruism‚Äîall of which depend on understanding the intention behind the action.

---

### The Mirror Neuron System: The Basis of Empathy üëØ

Discovered in the 1990s, **mirror neurons** are a class of brain cells that fire both when you **perform** an action and when you **observe** someone else performing that same action.

For example, when you see someone smile, your mirror neurons associated with smiling fire, giving you an internal simulation of that feeling.This system is believed to be the neural basis of **empathy** and imitation. It's how we can intuitively and automatically grasp what others are feeling and doing, creating a shared experience that bridges the gap between our individual minds. It‚Äôs a key reason our "maps" feel so similar‚Äîour brains are built to physically mirror each other.

---

### Emotional Processing: Sharing the Feeling

Beyond just understanding another's perspective, social intelligence involves processing and even sharing their emotions. Key brain regions handle this:

- The **Amygdala** acts as an emotional alarm, rapidly detecting emotionally significant cues in others, like a fearful expression.
- The **Insula** is involved in interoception‚Äîthe sense of your own body's internal state.When you empathise with someone's disgust or pain, your insula becomes active, creating a representation of that feeling in your own body.

This creates two forms of empathy:

1. **Cognitive Empathy:** "I understand what you're feeling." (Theory of Mind)
2. **Affective Empathy:** "I feel what you're feeling." (Mirror Neurons and Emotional Centres)

---

### Social Scripts and Norms: The Shared Playbook

Finally, our brains are exceptionally good at learning and internalising the unwritten rules, rituals, and **social scripts** of our culture. From how to greet someone to the expected flow of a conversation, these learned models provide a shared framework for interaction. They act like pre-loaded software that reduces the cognitive load of every social encounter, allowing us to collaborate smoothly because everyone is working from a similar playbook.

Together, these systems create a powerful suite of tools that allow us to construct remarkably similar social models, enabling the complex communication and cooperation that define our species.

Google Account

Leon Ormes

<leonormes@gmail.com>

The hermeneutic circle problem of the criterion is a fundamental epistemological challenge that arises in the process of interpretation and understanding. This problem manifests in several interconnected ways:

The Core Dilemma

The hermeneutic circle describes the interpretive process where understanding emerges through "an ongoing relationship between parts and wholes"[2]. The problem of the criterion emerges because to understand any part of a text, phenomenon, or meaningful human action, you need to understand the whole context - but to understand the whole, you need to understand its constituent parts[1][5].

The Circular Nature of Interpretation

This creates a circular dependency where[6] "in trying to understand an author (or another language, etc.) one finds oneself involved in the dilemma" of needing prior understanding to achieve understanding. The interpreter must somehow enter this circle of meaning without having a neutral, objective starting point.

Methodological Implications

The hermeneutic circle "serves as a standard argument for all those who raise a claim to the autonomy of the human sciences"[4][7]. This is because it highlights how interpretation in the humanities differs fundamentally from empirical observation in the natural sciences - there is no purely objective criterion external to the interpretive process itself.

Practical Applications

In fields like Human-Computer Interaction (HCI), this problem manifests when researchers "interpret and/or evaluate an interaction: the criteria by which we evaluate or interpret"[3] are themselves embedded within interpretive frameworks. The researcher's own "reasoning contexts, on which the researcher's interpretation is based"[8] become part of the hermeneutic circle.

The Criterion Problem

The specific "problem of the criterion" refers to the impossibility of establishing neutral, pre-given standards for interpretation. Any criteria used to judge the validity of an interpretation are themselves products of interpretive processes, creating an infinite regress or circular justification.

This problem doesn't necessarily invalidate hermeneutical approaches but rather highlights the inherently contextual and dialogical nature of human understanding, where meaning emerges through the dynamic interaction between interpreter, text, and context rather than through the application of universal, objective criteria.

References:

[2]: <https://www.simplypsychology.org/hermeneutic-circle.html>
[3]: <https://interactionculture.net/2009/03/09/two-takes-on-the-hermeneutic-circle/>
[5]: <https://plato.stanford.edu/archives/fall2016/entries/hermeneutics/>
[6]: <https://dukespace.lib.duke.edu/bitstreams/ba1f075f-4416-45dd-851d-a0feacce1830/download>
[7]: <https://www.cambridge.org/core/books/philosophy-of-the-social-sciences/what-kind-of-problem-is-the-hermeneutic-circle/681C26DB8C0A7AB0B7A3D0A20E310278>
[8]: <https://pubmed.ncbi.nlm.nih.gov/18271791/>
