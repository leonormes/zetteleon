{"assets":[{"title":"Kubernetes Configuration for Custom Kubernetes System","id":"173940ce-13e9-414e-b893-e30560dc5586","type":"CODE","raw":"apiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: \"2025-06-25T16:53:13Z\"\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n  name: coredns-custom\n  namespace: kube-system\n  resourceVersion: \"395\"\n  uid: 61660d0e-82b9-4bf5-9170-89e14209702c\ndata:\n  onprem-sql.override: |\n    hosts {\n      10.252.169.98 GBCBGPCISQ001.net.addenbrookes.nhs.uk\n      }","language":"yaml","time":"4 months ago","created":"2025-08-05T11:03:57.040Z","annotations":[],"updated":"2025-08-05T14:40:43.411Z"},{"title":"Restart CoreDNS and Verify with Debug Pod","id":"07746667-82f6-454b-a75a-96f8e5672a79","type":"CODE","raw":"# Restart CoreDNS\nkubectl rollout restart deployment coredns -n kube-system\n\n# Wait for the restart to complete\nkubectl rollout status deployment/coredns -n kube-system\n\n# Verify with a debug pod\nkubectl run -it --rm --image=nicolaka/netshoot dns-test -- /bin/bash -c \"dig GBCBGPCISQ001.net.addenbrookes.nhs.uk\"","language":"sh","time":"4 months ago","created":"2025-08-05T11:10:45.401Z","annotations":[],"updated":"2025-11-08T12:11:16.362Z"},{"title":"FITFILE Organization and Domain Configuration","id":"07cccc4d-ea81-4dee-93ae-bdb19787bce6","type":"CODE","raw":"organization      = \"FITFILE\"\nroot_common_name  = \"FITFILE Root CA\"\nint_common_name   = \"EOE SDE Intermediate CA\"\ndomain            = \"fitfile.co.uk\"\nallowed_domains   = [\"fitfile.co.uk\", \"*.fitfile.co.uk\"]\ncert_country      = \"GB\"\ncert_province     = \"London\"\ncert_locality     = \"London\"\ncert_ttl          = 720 # 30 days","language":"tf","time":"4 months ago","created":"2025-08-05T13:23:45.743Z","annotations":[],"updated":"2025-08-06T08:52:59.035Z"},{"title":"Kubernetes Proxy for Internal Services","id":"685d16b5-b1c4-49d6-9d0b-467b33d32cc0","type":"CODE","raw":"Absolutely! To ensure your Kubernetes pods bypass the proxy for all internal services, you should include **all forms** of each service's DNS name in your `NO_PROXY` (and `no_proxy`) environment variable. This is especially important in Kubernetes, where services may be accessed by short name, namespace-qualified name, or full FQDN.\n\nBelow is a detailed guide and a ready-to-use list for your `cuh-prod-1` namespace, based on your current services.\n\n---\n\n## 1. **Service List and All DNS Forms**\n\nFrom your output:\n```text\nkubectl get svc -n cuh-prod-1\nNAME\ncuh-prod-1-ffcloud-service\ncuh-prod-1-fitconnect-ftc\ncuh-prod-1-frontend-frontend\ncuh-prod-1-minio\ncuh-prod-1-mongodb-b17ef-arbiter-headless\ncuh-prod-1-mongodb-b17ef-headless\ncuh-prod-1-mongodb-b17ef-metrics\ncuh-prod-1-postgresql\ncuh-prod-1-postgresql-hl\nmutating-proxy-webhook\nworkflows-api\n```\n\nFor each service, you should include:\n- The short name (e.g., `cuh-prod-1-ffcloud-service`)\n- The namespace-qualified name (e.g., `cuh-prod-1-ffcloud-service.cuh-prod-1`)\n- The full FQDN (e.g., `cuh-prod-1-ffcloud-service.cuh-prod-1.svc.cluster.local`)\n\n---\n\n## 2. **Recommended NO_PROXY List**\n\nHereâ€™s a comprehensive list for your `NO_PROXY` variable, including all forms for each service, plus the standard Kubernetes suffixes and localhost:\n\n```env\nNO_PROXY=localhost,127.0.0.1,\\\ncuh-prod-1-ffcloud-service,\\\ncuh-prod-1-ffcloud-service.cuh-prod-1,\\\ncuh-prod-1-ffcloud-service.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-fitconnect-ftc,\\\ncuh-prod-1-fitconnect-ftc.cuh-prod-1,\\\ncuh-prod-1-fitconnect-ftc.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-frontend-frontend,\\\ncuh-prod-1-frontend-frontend.cuh-prod-1,\\\ncuh-prod-1-frontend-frontend.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-minio,\\\ncuh-prod-1-minio.cuh-prod-1,\\\ncuh-prod-1-minio.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-mongodb-b17ef-arbiter-headless,\\\ncuh-prod-1-mongodb-b17ef-arbiter-headless.cuh-prod-1,\\\ncuh-prod-1-mongodb-b17ef-arbiter-headless.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-mongodb-b17ef-headless,\\\ncuh-prod-1-mongodb-b17ef-headless.cuh-prod-1,\\\ncuh-prod-1-mongodb-b17ef-headless.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-mongodb-b17ef-metrics,\\\ncuh-prod-1-mongodb-b17ef-metrics.cuh-prod-1,\\\ncuh-prod-1-mongodb-b17ef-metrics.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-postgresql,\\\ncuh-prod-1-postgresql.cuh-prod-1,\\\ncuh-prod-1-postgresql.cuh-prod-1.svc.cluster.local,\\\ncuh-prod-1-postgresql-hl,\\\ncuh-prod-1-postgresql-hl.cuh-prod-1,\\\ncuh-prod-1-postgresql-hl.cuh-prod-1.svc.cluster.local,\\\nmutating-proxy-webhook,\\\nmutating-proxy-webhook.cuh-prod-1,\\\nmutating-proxy-webhook.cuh-prod-1.svc.cluster.local,\\\nworkflows-api,\\\nworkflows-api.cuh-prod-1,\\\nworkflows-api.cuh-prod-1.svc.cluster.local,\\\n.svc,.svc.cluster.local\n```\n\n**Tip:**  \n- The `.svc` and `.svc.cluster.local` suffixes ensure that any Kubernetes service (in any namespace) will bypass the proxy.\n- Always include both uppercase (`NO_PROXY`) and lowercase (`no_proxy`) variants for maximum compatibility.\n\n---\n\n## 3. **How to Update in Your Deployment**\n\nIn your Kubernetes deployment YAML, update the environment section like this:\n\n```yaml\nenv:\n  - name: NO_PROXY\n    value: \"localhost,127.0.0.1,cuh-prod-1-ffcloud-service,cuh-prod-1-ffcloud-service.cuh-prod-1,cuh-prod-1-ffcloud-service.cuh-prod-1.svc.cluster.local,...,.svc,.svc.cluster.local\"\n  - name: no_proxy\n    value: \"localhost,127.0.0.1,cuh-prod-1-ffcloud-service,cuh-prod-1-ffcloud-service.cuh-prod-1,cuh-prod-1-ffcloud-service.cuh-prod-1.svc.cluster.local,...,.svc,.svc.cluster.local\"\n```\n*(Replace `...` with the rest of the entries from the list above.)*\n\n---\n\n## 4. **Why This Matters**\n\n- **Short form**: Used by apps in the same namespace.\n- **Namespace-qualified**: Used by apps in other namespaces.\n- **FQDN**: Used by some libraries and for cross-namespace communication.\n- **Suffixes**: Catch-all for any future services.\n\nIf you only use one form, some requests may still go through the proxy, causing failures (like the 407 Proxy Authentication Required you saw for `spicedb`).\n\n---\n\n## 5. **References**\n\n- [Kubernetes DNS for Services and Pods](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/)\n- [NO_PROXY and FQDNs in Kubernetes](https://github.com/kubernetes/kubernetes/issues/32286)\n\n---\n\n**Let me know if you want a script to generate this list automatically, or if you need help patching your deployment YAMLs!**","language":"md","time":"4 months ago","created":"2025-08-04T09:27:19.833Z","annotations":[],"updated":"2025-11-08T12:15:18.811Z"},{"title":"FitFile Root CA","id":"4a3e7a30-7ae0-45f5-8156-64bc24b2aff2","type":"CODE","raw":"ðŸ‘‘ FitFile Root CA (in HCP Vault, highly secured)\n       â”‚\n       â”œâ”€â”€ signs --> ðŸ¢ SDE Intermediate CA\n       â”‚             â”‚\n       â”‚             â””â”€â”€ issues certs for --> *.sde.fitfile.net\n       â”‚\n       â”œâ”€â”€ signs --> ðŸ¢ CUH Intermediate CA\n       â”‚             â”‚\n       â”‚             â””â”€â”€ issues certs for --> *.cuh.fitfile.net\n       â”‚\n       â””â”€â”€ signs --> ðŸ¢ New Customer Intermediate CA\n                     â”‚\n                     â””â”€â”€ issues certs for --> *.newcustomer.fitfile.net","language":"md","time":"4 months ago","created":"2025-08-06T14:08:48.776Z","annotations":[],"updated":"2025-08-06T14:08:51.799Z"},{"title":"Variable Variables for Root CA PKI Engine","id":"e62c360a-be51-4e9f-9425-9e56c8dee772","type":"CODE","raw":"# -----------------------------------------------------------------------------\n# VARIABLES\n# -----------------------------------------------------------------------------\nvariable \"organization\" {\n  description = \"Organisation name for certificates\"\n  type        = string\n  default     = \"FitFile Inc\"\n}\n\nvariable \"pki_root_path\" {\n  description = \"Path for the Root PKI Secrets Engine\"\n  type        = string\n  default     = \"pki_root_fitfile\"\n}\n\nvariable \"pki_int_path\" {\n  description = \"Path for the Intermediate PKI Secrets Engine\"\n  type        = string\n  default     = \"pki_int_fitfile\"\n}\n\nvariable \"kubernetes_auth_path\" {\n  description = \"Path for the Kubernetes authentication backend\"\n  type        = string\n  default     = \"kubernetes_eks_prod\"\n}\n\nvariable \"allowed_domains\" {\n  description = \"List of allowed domains for certificate issuance\"\n  type        = list(string)\n  default     = [\"fitfile.net\"]\n}\n\nvariable \"kubernetes_host\" {\n  description = \"Kubernetes API URL for the EKS cluster\"\n  type        = string\n}\n\nvariable \"kubernetes_ca_cert\" {\n  description = \"PEM-encoded CA certificate for the Kubernetes API\"\n  type        = string\n  sensitive   = true\n}\n\nvariable \"token_reviewer_jwt\" {\n  description = \"A long-lived Kubernetes service account token that has permission to perform TokenReview\"\n  type        = string\n  sensitive   = true\n}\n\n# -----------------------------------------------------------------------------\n# ROOT CA SETUP\n# -----------------------------------------------------------------------------\nresource \"vault_mount\" \"pki_root\" {\n  path        = var.pki_root_path\n  type        = \"pki\"\n  description = \"FitFile Root CA PKI Engine\"\n  # 20 year max TTL for the root\n  max_lease_ttl_seconds = 630720000\n}\n\nresource \"vault_pki_secret_backend_root_cert\" \"root\" {\n  depends_on = [vault_mount.pki_root]\n\n  backend     = vault_mount.pki_root.path\n  type        = \"internal\"\n  common_name = \"FitFile Root CA\"\n  # 10 year TTL for the root certificate\n  ttl         = \"87600h\"\n  key_type    = \"rsa\"\n  key_bits    = 4096\n  organization = var.organization\n}\n\n# -----------------------------------------------------------------------------\n# INTERMEDIATE CA SETUP\n# -----------------------------------------------------------------------------\nresource \"vault_mount\" \"pki_int\" {\n  path        = var.pki_int_path\n  type        = \"pki\"\n  description = \"FitFile Intermediate CA PKI Engine\"\n  # 5 year max TTL for the intermediate\n  max_lease_ttl_seconds = 157680000\n}\n\nresource \"vault_pki_secret_backend_intermediate_cert_request\" \"intermediate\" {\n  depends_on = [vault_mount.pki_int]\n\n  backend     = vault_mount.pki_int.path\n  type        = \"internal\"\n  common_name = \"FitFile Intermediate CA\"\n}\n\nresource \"vault_pki_secret_backend_root_sign_intermediate\" \"intermediate\" {\n  depends_on = [vault_pki_secret_backend_root_cert.root]\n\n  backend     = vault_mount.pki_root.path\n  csr         = vault_pki_secret_backend_intermediate_cert_request.intermediate.csr\n  common_name = \"FitFile Intermediate CA\"\n  # 3 year TTL for the intermediate certificate\n  ttl         = \"26280h\"\n  format      = \"pem_bundle\"\n}\n\nresource \"vault_pki_secret_backend_intermediate_set_signed\" \"intermediate\" {\n  backend     = vault_mount.pki_int.path\n  certificate = vault_pki_secret_backend_root_sign_intermediate.intermediate.certificate\n}\n\n# -----------------------------------------------------------------------------\n# CERT-MANAGER ROLE & POLICY\n# -----------------------------------------------------------------------------\nresource \"vault_pki_secret_backend_role\" \"cert_manager_role\" {\n  depends_on = [vault_pki_secret_backend_intermediate_set_signed.intermediate]\n\n  backend          = vault_mount.pki_int.path\n  name             = \"cert-manager-role\"\n  allowed_domains  = var.allowed_domains\n  allow_subdomains = true\n  # 30 day TTL for leaf certificates\n  max_ttl          = \"720h\"\n}\n\nresource \"vault_policy\" \"cert_manager_policy\" {\n  name = \"cert-manager-policy\"\n\n  policy = <<EOT\n# Allow cert-manager to sign certificates using its role\npath \"${vault_mount.pki_int.path}/sign/${vault_pki_secret_backend_role.cert_manager_role.name}\" {\n  capabilities = [\"create\", \"update\"]\n}\nEOT\n}\n\n# -----------------------------------------------------------------------------\n# KUBERNETES AUTHENTICATION\n# -----------------------------------------------------------------------------\nresource \"vault_auth_backend\" \"kubernetes\" {\n  type = \"kubernetes\"\n  path = var.kubernetes_auth_path\n}\n\nresource \"vault_kubernetes_auth_backend_config\" \"config\" {\n  backend            = vault_auth_backend.kubernetes.path\n  kubernetes_host    = var.kubernetes_host\n  kubernetes_ca_cert = var.kubernetes_ca_cert\n  token_reviewer_jwt = var.token_reviewer_jwt\n}\n\nresource \"vault_kubernetes_auth_backend_role\" \"cert_manager_auth\" {\n  backend                          = vault_auth_backend.kubernetes.path\n  role_name                        = \"cert-manager\"\n  bound_service_account_names      = [\"cert-manager\"]\n  bound_service_account_namespaces = [\"cert-manager\"]\n  token_policies                   = [vault_policy.cert_manager_policy.name]\n  token_ttl                        = 3600 # 1 hour\n}","language":"tf","time":"4 months ago","created":"2025-08-04T10:48:48.283Z","annotations":[],"updated":"2025-11-01T14:58:40.449Z"},{"title":"Show Private DNS Zone","id":"c4bb8ac3-3128-4ddf-a743-5a56346e4a96","type":"CODE","raw":"az network private-dns zone show --resource-group rg-ff-uks-gp-net --name privatelink.fitfile.net --query \"properties.privateZoneNameConfiguration.privateDnsZoneConfigs[0].privateIpAddress\" -o tsv","language":"sh","time":"3 months ago","created":"2025-08-12T10:51:14.780Z","annotations":[],"updated":"2025-08-12T10:51:16.782Z"},{"title":"Regex for Regular Patterns","id":"1b9f4a08-c8b2-409e-bd30-51add857e7f8","type":"CODE","raw":":%s/ \\[[0-9,\\- ]\\+\\]//g\n","language":"sh","time":"about a month ago","created":"2025-10-16T14:04:45.885Z","annotations":[],"updated":"2025-10-25T11:11:48.808Z"},{"title":"HCP Vault Cluster Issuer Configuration","id":"f20fa0cf-e104-4b70-9b76-0e65ff23e90d","type":"CODE","raw":"# hcp-vault-clusterissuer.yaml\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: hcp-vault-issuer\nspec:\n  vault:\n    # Your HCP Vault server address (ensure it's reachable from EKS)\n    server: \"https://your-vault-cluster.private.vault.cloud:8200\"\n    # The path where you enabled the Kubernetes auth method\n    path: \"kubernetes_eks_prod\"\n    # The Kubernetes auth role you created in Terraform\n    role: \"cert-manager\"\n    # The full path to the signing endpoint in the intermediate CA\n    pkiPath: \"pki_int_fitfile/sign/cert-manager-role\"","language":"yaml","time":"4 months ago","created":"2025-08-04T10:49:03.938Z","annotations":[],"updated":"2025-08-11T17:45:43.390Z"},{"title":"Set Private DNS records for IPv6","id":"23232423-3428-4c4b-9bcd-1cd0a57e4c1b","type":"CODE","raw":"az network private-dns record-set a list -g rg-ff-uks-gp-net -z privatelink.fitfile.net\naz network private-dns record-set aaaa list -g rg-ff-uks-gp-net -z privatelink.fitfile.net # For IPv6 records","language":"sh","time":"3 months ago","created":"2025-08-12T11:40:30.491Z","annotations":[],"updated":"2025-08-12T11:40:32.496Z"},{"title":"GitHub Container Registry Authenticate and Pull Private Image","id":"6228d52e-5435-441a-ab91-b44ab618cd6f","type":"CODE","raw":"# Authenticate to GitHub Container Registry (ghcr.io)\n# Commands to Authenticate Docker to ghcr.io\n# Refresh GitHub CLI Token with read:packages Scope\n\ngh auth refresh -h github.com -s read:packages\n\n# Use the Token to Authenticate Docker\n\ngh auth token | docker login ghcr.io -u leonormes --password-stdin\n\n# Example: Pull a Private Image\n\ndocker pull ghcr.io/thehyve/fitfile_etl_container_mkuh:0.4.3-test\naz acr login --name fitfileregistry\ndocker tag ghcr.io/thehyve/fitfile_etl_container_mkuh:0.4.4-test fitfileregistry.azurecr.io/thehyve/fitfile_etl_container_mkuh:0.4.4-test\ndocker push fitfileregistry.azurecr.io/thehyve/fitfile_etl_container_mkuh:0.4.4-test\n","language":"sh","time":"about a month ago","created":"2025-10-24T09:33:47.255Z","annotations":[],"updated":"2025-11-08T12:12:55.601Z"},{"title":"Nodepool Upgrade with Image Only","id":"199720ad-81d4-4993-a0cb-8d9013ad02ca","type":"CODE","raw":"az aks nodepool upgrade \\\n--resource-group rg-ff-uks-gp-net \\\n--cluster-name aks-ff-uks-gp-01 \\\n--name system \\\n--node-image-only","language":"sh","time":"4 months ago","created":"2025-08-04T15:27:40.716Z","annotations":[],"updated":"2025-08-04T16:58:18.538Z"},{"title":"VPC Subnets and Route Tables for Internet Gateway","id":"910bfd79-05b6-4b4a-bb2c-c0087abb6489","type":"CODE","raw":"# 1. List all subnets in your VPC\n# Replace VPC_ID with your VPC ID\naws ec2 describe-subnets --filters \"Name=vpc-id,Values=VPC_ID\" \\\n  --query 'Subnets[].[SubnetId, CidrBlock, MapPublicIpOnLaunch, Tags[?Key==`Name`].Value | [0], AvailabilityZone]' \\\n  --output table\n\n# 2. Check route tables for public subnets (look for routes to Internet Gateway)\naws ec2 describe-route-tables \\\n  --filters \"Name=vpc-id,Values=VPC_ID\" \\\n  --query 'RouteTables[].[Associations[].SubnetId, Routes[?GatewayId!=null && starts_with(GatewayId, 'igw-')]]' \\\n  --output table\n\n# 3. Check for existing NAT Gateways\naws ec2 describe-nat-gateways \\\n  --filter \"Name=vpc-id,Values=VPC_ID\" \\\n  --query 'NatGateways[?State==`available`].[NatGatewayId, SubnetId, NatGatewayAddresses[0].PublicIp]' \\\n  --output table\n\n# 4. Check for existing Internet Gateways\naws ec2 describe-internet-gateways \\\n  --filters \"Name=attachment.vpc-id,Values=VPC_ID\" \\\n  --query 'InternetGateways[*].InternetGatewayId' \\\n  --output text","language":"sh","time":"3 months ago","created":"2025-08-13T09:08:23.279Z","annotations":[],"updated":"2025-11-01T15:01:46.447Z"},{"title":"Environment Variables for Vault Secrets","id":"e8ca6fd6-ee45-462e-820b-3cfe46993961","type":"CODE","raw":"extraEnvVars:\n  - name: NHS_SITE\n    value: mkuh\n  # Existing Vault secrets\n  - name: QCR_BUCKET\n    valueFrom:\n      secretKeyRef:\n        name: thehyve\n        key: qcr_bucket\n  # Add your new secret reference:\n  - name: YOUR_SECRET_VAR\n    valueFrom:\n      secretKeyRef:\n        name: thehyve\n        key: your_secret_key\n","language":"yaml","time":"30 days ago","created":"2025-10-25T11:40:27.537Z","annotations":[],"updated":"2025-10-25T11:40:30.283Z"},{"title":"Update aks with proxy configuration","id":"dc44aa75-5f96-4184-9d82-94388106e334","type":"CODE","raw":"az aks update \\\n--name aks-ff-uks-gp-01 \\\n--resource-group rg-ff-uks-gp-net \\\n--http-proxy-config ./proxy-config.json","language":"sh","time":"4 months ago","created":"2025-08-04T15:46:50.875Z","annotations":[],"updated":"2025-08-04T15:50:00.230Z"},{"title":"Kubectl run with image pull secret.","id":"34b78626-d7ee-4c8f-847b-44a6625e0294","type":"CODE","raw":"kubectl run -it --rm --image=fitfileregistry.azurecr.io/busybox:latest dns-test3 -n cuh-prod-1 \\\n--overrides='{ \"spec\": { \"template\": { \"spec\": { \"imagePullSecrets\": [{\"name\": \"fitfile-image-pull-secret\"}] } } } }' \\\n-- /bin/sh","language":"sh","time":"3 months ago","created":"2025-08-13T11:11:58.165Z","annotations":[],"updated":"2025-08-13T13:49:10.309Z"},{"title":"AWS sso login discovery access.","id":"7705508e-ddad-400f-8554-8dbadcbc5ac3","type":"CODE","raw":"aws sso login --profile discovery-access\n","language":"sh","time":"23 days ago","created":"2025-11-01T15:10:19.920Z","annotations":[],"updated":"2025-11-03T13:14:48.569Z"},{"title":"kubectl debug node with image.","id":"dabbe341-3c17-4a46-a5a4-f2bb7ecd76d7","type":"CODE","raw":"kubectl debug node/aks-system-23892849-vmss000002 -it --image=mcr.microsoft.com/cbl-mariner/base/core:2.0\n","language":"sh","time":"4 months ago","created":"2025-08-04T15:47:44.586Z","annotations":[],"updated":"2025-08-13T10:52:29.945Z"},{"title":"EIP Address Validation for NAT Gateway","id":"7930129c-d011-4d58-a055-514342c086bb","type":"CODE","raw":"# Check the NAT Gateway details\naws ec2 describe-nat-gateways --nat-gateway-ids nat-02c1a6d832f6683e5\n\n# Check the EIP details\naws ec2 describe-addresses --allocation-ids eipalloc-0c7a6709d25c111cd","language":"sh","time":"3 months ago","created":"2025-08-14T10:56:28.459Z","annotations":[],"updated":"2025-11-03T13:16:57.175Z"},{"title":"Check if image version is provided","id":"99dad9fc-31b6-4f19-ad3b-da67a2e1f9fe","type":"CODE","raw":"#!/bin/bash\n\n# Check if an image version is provided\nif [ -z \"$1\" ]; then\n  echo \"Usage: $0 <image_version>\"","language":"sh","time":"16 days ago","created":"2025-11-08T12:02:58.880Z","annotations":[],"updated":"2025-11-08T12:03:00.871Z"},{"title":"Azure Cluster Upgrade","id":"b9128a46-c471-4745-b013-0b004abb2730","type":"CODE","raw":"az aks upgrade \\\n--resource-group rg-ff-uks-gp-net \\\n--name aks-ff-uks-gp-01 \\\n--node-image-only \\\n--yes","language":"sh","time":"4 months ago","created":"2025-08-04T15:57:01.923Z","annotations":[],"updated":"2025-08-13T12:15:12.390Z"},{"title":"Fetch Vulnerability Reports from Kubernetes","id":"3d94f585-01a3-44d4-9304-c05d275a16b8","type":"CODE","raw":"import json\nimport subprocess\nfrom datetime import datetime\nimport requests\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ntop_vulns_count = 5\nmin_score = 6\n\ndef fetch_description(vuln_id):\n    nvd_url = f\"https://access.redhat.com/hydra/rest/securitydata/cve/{vuln_id}\"\n    try:\n        response = requests.get(nvd_url, timeout=10)\n        data = response.json()\n        # description = data.get(\"bugzilla\", {}).get(\"description\")\n        description = data.get(\"details\", {})\n\n        if description:\n            return description\n    except Exception as e:\n        return f\"Description not available (error: {e})\"\n    return \"Description not available\"\n\nprint(\"ðŸ” Retrieving vulnerability reports from Kubernetes...\")\nresult = subprocess.run(\n    [\"kubectl\", \"get\", \"vulnerabilityreports\", \"-A\", \"-o\", \"json\"],\n    capture_output=True, text=True\n)\n\nvuln_reports = json.loads(result.stdout)\nseverity_groups = {\"CRITICAL\": [], \"HIGH\": [], \"MEDIUM\": [], \"LOW\": []}\nvuln_tasks = []\n\nprint(\"ðŸ“Š Processing vulnerabilities and preparing description fetch tasks...\")\nfor item in tqdm(vuln_reports.get(\"items\", []), desc=\"Processing reports\"):\n    namespace = item[\"metadata\"][\"namespace\"]\n    name = item[\"metadata\"][\"name\"]\n    vulnerabilities = item.get(\"report\", {}).get(\"vulnerabilities\", [])\n\nfor vuln in vulnerabilities:\n    vuln_id = vuln.get(\"vulnerabilityID\")\n    severity = vuln.get(\"severity\")\n    score = vuln.get(\"score\")\n    if severity in severity_groups and vuln_id not in [v[\"vulnerability_id\"] for v in severity_groups[severity]] and score is not None and score >= min_score:\n        pkg_name = vuln.get(\"pkgName\")\n        vuln_data = {\n            \"namespace\": namespace,\n            \"report_name\": name,\n            \"vulnerability_id\": vuln_id,\n            \"resource\": vuln.get(\"resource\"),\n            \"severity\": severity,\n            \"score\": score,\n            \"title\": vuln.get(\"title\"),\n            \"redhat_url\": f\"https://access.redhat.com/security/cve/{vuln_id}\",\n            \"nvd_url\": f\"https://nvd.nist.gov/vuln/detail/{vuln_id}\"\n        }\n        severity_groups[severity].append(vuln_data)\n        vuln_tasks.append((vuln_id, vuln_data))\n\nprint(\"âš¡ Fetching vulnerability descriptions concurrently...\")\n# with ThreadPoolExecutor(max_workers=16) as executor:\n#     future_to_vuln = {executor.submit(fetch_description, vuln_id): vuln_data for vuln_id, vuln_data in vuln_tasks}\n#     for future in tqdm(as_completed(future_to_vuln), total=len(future_to_vuln), desc=\"Fetching descriptions\"):\n#         vuln_data = future_to_vuln[future]\n#         try:\n#             description = future.result()\n#         except Exception as e:\n#             description = f\"Description not available (error: {e})\"\n#         vuln_data[\"description\"] = description\n\nprint(f\"ðŸ“Œ Selecting top {top_vulns_count} vulnerabilities for each severity level, where the miniumum score is {min_score}...\")\ntop_vulnerabilities = {}\nfor severity, vulns in severity_groups.items():\n    sorted_vulns = sorted(vulns, key=lambda x: x[\"score\"] if x[\"score\"] is not None else 0, reverse=True)\n    top_vulnerabilities[severity] = sorted_vulns[:top_vulns_count]\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nfilename = f\"top_vulnerabilities_all_severities_{timestamp}.json\"\n\nwith open(filename, \"w\") as f:\n    json.dump(top_vulnerabilities, f, indent=2)\n\nprint(f\"âœ… Report saved to '{filename}'\")","language":"py","time":"3 months ago","created":"2025-08-28T10:10:13.226Z","annotations":[],"updated":"2025-11-08T12:10:54.450Z"},{"title":"Image Version Validation and GitHub Authentication","id":"918e1967-6c60-421e-8806-0c9852659127","type":"CODE","raw":"#!/bin/bash\n\n# Check if an image version is provided\nif [ -z \"$1\" ]; then\n  echo \"Usage: $0 <image_version>\"\n  echo \"Example: $0 0.4.4-test\"\n  exit 1\nfi\n\nIMAGE_VERSION=\"$1\"\nGHCR_REGISTRY=\"ghcr.io\"\nGHCR_REPO=\"thehyve/fitfile_etl_container_mkuh\"\nACR_REGISTRY_NAME=\"fitfileregistry\"\nACR_LOGIN_SERVER=\"${ACR_REGISTRY_NAME}.azurecr.io\"\nACR_REPO=\"thehyve/fitfile_etl_container_mkuh\" # Assuming same repo name in ACR as GHCR\n\nGHCR_FULL_IMAGE=\"${GHCR_REGISTRY}/${GHCR_REPO}:${IMAGE_VERSION}\"\nACR_FULL_IMAGE=\"${ACR_LOGIN_SERVER}/${ACR_REPO}:${IMAGE_VERSION}\"\n\necho \"--- Authenticating to GitHub Container Registry (ghcr.io) ---\"\n# Refresh GitHub CLI Token with read:packages Scope\ngh auth refresh -h github.com -s read:packages || { echo \"Failed to refresh GitHub token.\"; exit 1; }\n\n# Use the Token to Authenticate Docker to ghcr.io\ngh auth token | docker login \"${GHCR_REGISTRY}\" -u leonormes --password-stdin || { echo \"Failed to login to GHCR.\"; exit 1; }\necho \"Successfully logged into ghcr.io\"\n\necho \"--- Pulling image from GitHub Container Registry ---\"\ndocker pull \"${GHCR_FULL_IMAGE}\" || { echo \"Failed to pull image from GHCR: ${GHCR_FULL_IMAGE}\"; exit 1; }\necho \"Successfully pulled ${GHCR_FULL_IMAGE}\"\n\necho \"--- Authenticating to Azure Container Registry (${ACR_REGISTRY_NAME}) ---\"\naz acr login --name \"${ACR_REGISTRY_NAME}\" || { echo \"Failed to login to Azure Container Registry.\"; exit 1; }\necho \"Successfully logged into ${ACR_REGISTRY_NAME}\"\n\necho \"--- Tagging image for Azure Container Registry ---\"\ndocker tag \"${GHCR_FULL_IMAGE}\" \"${ACR_FULL_IMAGE}\" || { echo \"Failed to tag image.\"; exit 1; }\necho \"Successfully tagged ${GHCR_FULL_IMAGE} as ${ACR_FULL_IMAGE}\"\n\necho \"--- Pushing image to Azure Container Registry ---\"\ndocker push \"${ACR_FULL_IMAGE}\" || { echo \"Failed to push image to ACR: ${ACR_FULL_IMAGE}\"; exit 1; }\necho \"Successfully pushed ${ACR_FULL_IMAGE} to ${ACR_REGISTRY_NAME}\"\n\necho \"Script completed successfully.\"","language":"sh","time":"16 days ago","created":"2025-11-08T12:12:03.642Z","annotations":[],"updated":"2025-11-13T14:23:37.597Z"},{"title":"kubectl deployment restart with jsonpath","id":"43f572c2-e64a-439e-98fb-de46b13ed3c7","type":"CODE","raw":"kubectl get deployments --all-namespaces -o jsonpath='{range .items[*]}{.metadata.namespace} {.metadata.name}\\n{end}' | while read ns name; do kubectl rollout restart deployment \"$name\" -n \"$ns\"; done","language":"sh","time":"4 months ago","created":"2025-08-05T08:56:36.852Z","annotations":[],"updated":"2025-08-05T09:19:36.383Z"},{"title":"Discover Images in Chart","id":"98defb65-bddc-46c8-b87c-28ffc334890a","type":"CODE","raw":"discover_images_in_chart() {\n    local chart_dir=\"$1\"\n\n    if [ ! -d \"$chart_dir\" ]; then\n        echo \"Error: Chart directory '$chart_dir' not found.\" >&2\n        return 1\n    fi\n\n    # Method 1: Use helm template to render the chart and extract image references\n    local rendered_images=\"\"\n    if command -v helm &> /dev/null; then\n        rendered_images=$(helm template \"$chart_dir\" 2>/dev/null | \\\n            grep -E 'image:' | \\\n            sed -e 's/^[[:space:]]*image:[[:space:]]*//' -e 's/\"//g' -e \"s/'//g\" | \\\n            grep -E '^[a-zA-Z0-9./_-]+:[a-zA-Z0-9._-]+$' | \\\n            sort -u\n        )\n    fi\n\n    # Method 2: Extract from values.yaml for simple repository and tag combinations.\n    local values_images=\"\"\n    if [ -f \"$chart_dir/values.yaml\" ]; then\n        values_images=$(yq eval '.. | select(has(\"repository\") and has(\"tag\")) | .repository + \":\" + .tag' \"$chart_dir/values.yaml\" 2>/dev/null)\n    fi\n\n    # Combine, sort, and unique the results from all methods\n    (echo \"$rendered_images\"; echo \"$values_images\") | \\\n        grep -v -e '^$' -e 'null' | \\\n        sort -u\n}\n","language":"sh","time":"3 months ago","created":"2025-09-05T15:55:06.393Z","annotations":[],"updated":"2025-11-08T12:13:26.260Z"},{"title":"Azure CLI Command with Environment Variables","id":"34942e01-7b5c-440b-9a20-a5642e01a1d1","type":"TEXT","raw":"#!/usr/bin/env python3\nimport argparse\nimport csv\nimport datetime as dt\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\nfrom typing import Dict, List, Tuple, Any, Optional\n\nAZ_ENV = {\"AZURE_CORE_ONLY_SHOW_ERRORS\": \"1\"}\n\ndef run_az(cmd: List[str], timeout: Optional[float] = None) -> Tuple[Optional[Any], Optional[str]]:\n    try:\n        p = subprocess.run(\n            [\"az\"] + cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            env={**os.environ, **AZ_ENV},\n            timeout=timeout,\n        )\n    except FileNotFoundError:\n        return None, \"Azure CLI (az) not found\"\n    except subprocess.TimeoutExpired:\n        return None, \"az command timed out\"\n    if p.returncode != 0:\n        return None, p.stderr.strip() or \"az command failed\"\n    try:\n        return json.loads(p.stdout), None\n    except Exception as e:\n        return None, f\"Failed to parse az JSON: {e}\"\n\ndef normalize_key(name: str) -> str:\n    return re.sub(r\"[^a-z0-9]\", \"\", name.lower())\n\ndef pick_field(row: Dict[str, str], candidates: List[str]) -> Optional[str]:\n    norm = {normalize_key(k): k for k in row.keys()}\n    for c in candidates:\n        cc = normalize_key(c)\n        if cc in norm:\n            return norm[cc]\n    return None\n\ndef extract_disk_id(row: Dict[str, str]) -> Optional[str]:\n    # Try direct resource id fields\n    possible_fields = [\n        \"ResourceId\", \"Resource ID\", \"resourceMetadata.resourceId\", \"ResourceUri\", \"ImpactedResourceId\", \"Impacted Resource Id\"\n    ]\n    field = pick_field(row, possible_fields)\n    rid = None\n    if field:\n        rid = (row.get(field) or \"\").strip()\n    # If not found or invalid, try reconstruct from sub/rg/name\n    if not rid or \"/providers/\" not in rid:\n        sub_f = pick_field(row, [\"SubscriptionId\", \"Subscription Guid\", \"SubscriptionGuid\", \"Subscription ID\"])\n        rg_f = pick_field(row, [\"ResourceGroup\", \"Resource Group\"])\n        name_f = pick_field(row, [\"ResourceName\", \"Resource Name\", \"ImpactedValue\"])\n        if sub_f and rg_f and name_f:\n            sub = (row.get(sub_f) or \"\").strip()\n            rg = (row.get(rg_f) or \"\").strip()\n            name = (row.get(name_f) or \"\").strip()\n            if sub and rg and name:\n                rid = f\"/subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.Compute/disks/{name}\"\n    if rid and \"/providers/microsoft.compute/disks/\" not in rid.lower():\n        return None\n    return rid\n\ndef parse_subscriptions() -> Dict[str, str]:\n    # Try to list subscriptions quickly; if it fails or is slow, fall back to IDs.\n    data, err = run_az([\"account\", \"subscription\", \"list\", \"-o\", \"json\"], timeout=10)\n    mapping: Dict[str, str] = {}\n    if err or not data:\n        return mapping\n    if isinstance(data, list):\n        for s in data:\n            sid = s.get(\"subscriptionId\")\n            name = s.get(\"displayName\") or s.get(\"name\") or \"\"\n            if sid:\n                mapping[sid] = name\n    return mapping\n\ndef portal_link(resource_id: str) -> str:\n    # Generic deep link without tenant scoping\n    return f\"https://portal.azure.com/#resource{resource_id}/overview\"\n\ndef get_disk(resource_id: str) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:\n    # Per-disk timeout to avoid long hangs\n    data, err = run_az([\"disk\", \"show\", \"--ids\", resource_id, \"-o\", \"json\"], timeout=20)\n    if err:\n        return None, err\n    return data, None\n\ndef is_attached(disk: Dict[str, Any]) -> bool:\n    props = disk.get(\"properties\") or {}\n    if props.get(\"managedBy\"):\n        return True\n    mbe = props.get(\"managedByExtended\")\n    if isinstance(mbe, list) and len(mbe) > 0:\n        return True\n    state = (props.get(\"diskState\") or \"\").lower()\n    if state in {\"attached\"}:\n        return True\n    return False\n\ndef human_tags(tags: Optional[Dict[str, str]]) -> str:\n    if not tags:\n        return \"-\"\n    parts = []\n    for k, v in tags.items():\n        parts.append(f\"{k}={v}\")\n    return \"; \".join(sorted(parts))\n\ndef now_iso() -> str:\n    return dt.datetime.now().astimezone().isoformat(timespec=\"seconds\")\n\ndef build_markdown(title: str,\n                   csv_path: str,\n                   generated_at: str,\n                   summary: Dict[str, Any],\n                   unattached_rows: List[Dict[str, Any]],\n                   excluded_rows: List[Dict[str, Any]],\n                   errors: List[Tuple[str, str]]) -> str:\n    lines = []\n    lines.append(\"---\")\n    lines.append(f'title: \"{title}\"')\n    lines.append(f\"date: {generated_at}\")\n    lines.append(\"tags: [azure, cost, advisor, disks]\")\n    lines.append(f'source_csv: \"{csv_path}\"')\n    lines.append(\"---\")\n    lines.append(\"\")\n    lines.append(f\"# {title}\")\n    lines.append(\"\")\n    lines.append(f\"- Generated: {generated_at}\")\n    lines.append(f\"- Source CSV: {csv_path}\")\n    lines.append(f\"- Selection: only disks listed in the Advisor CSV\")\n    lines.append(f\"- Portal links: included\")\n    lines.append(\"\")\n    lines.append(\"## Summary\")\n    lines.append(\"\")\n    lines.append(f\"- CSV candidate rows: {summary.get('csv_rows', 0)}\")\n    lines.append(f\"- Unique disk IDs in CSV: {summary.get('unique_ids', 0)}\")\n    lines.append(f\"- Resolved successfully: {summary.get('resolved', 0)}\")\n    lines.append(f\"- Unattached (included): {len(unattached_rows)}\")\n    lines.append(f\"- Excluded (attached or filtered): {len(excluded_rows)}\")\n    lines.append(f\"- Errors: {len(errors)}\")\n    lines.append(\"\")\n    lines.append(\"## Unattached disks (current state)\")\n    lines.append(\"\")\n    if not unattached_rows:\n        lines.append(\"_None found among the Advisor CSV candidates._\")\n    else:\n        lines.append(\"| Disk | Subscription | Resource Group | Region | SKU | Size (GiB) | OS | State | Tags | Portal |\")\n        lines.append(\"|---|---|---|---|---|---:|---|---|---|---|\")\n        for r in unattached_rows:\n            lines.append(\"| {name} | {subname} | {rg} | {loc} | {sku} | {size} | {os} | {state} | {tags} | [open]({plink}) |\".format(\n                name=r.get(\"name\",\"\"),\n                subname=r.get(\"subscriptionName\",\"\"),\n                rg=r.get(\"resourceGroup\",\"\"),\n                loc=r.get(\"location\",\"\"),\n                sku=r.get(\"sku\",\"\"),\n                size=r.get(\"sizeGb\",\"\"),\n                os=r.get(\"osType\",\"-\"),\n                state=r.get(\"state\",\"\"),\n                tags=r.get(\"tagsHuman\",\"-\"),\n                plink=r.get(\"portalLink\",\"\"),\n            ))\n    if excluded_rows:\n        lines.append(\"\")\n        lines.append(\"## Excluded items (not included in unattached list)\")\n        lines.append(\"\")\n        lines.append(\"| Disk | Reason | Current State | Portal |\")\n        lines.append(\"|---|---|---|---|\")\n        for r in excluded_rows:\n            lines.append(f\"| {r.get('name','')} | {r.get('excludeReason','')} | {r.get('state','')} | [open]({r.get('portalLink','')}) |\")\n    if errors:\n        lines.append(\"\")\n        lines.append(\"## Errors\")\n        lines.append(\"\")\n        lines.append(\"| Resource ID | Error |\")\n        lines.append(\"|---|---|\")\n        for rid, err in errors:\n            lines.append(f\"| {rid} | {err} |\")\n    lines.append(\"\")\n    lines.append(\"> Note: This report only evaluates the disks referenced by the provided Azure Advisor CSV. It verifies current attachment state live via Azure CLI.\")\n    return \"\\n\".join(lines)\n\ndef main():\n    ap = argparse.ArgumentParser(description=\"Generate a Markdown report of potentially unattached Azure managed disks from an Advisor CSV.\")\n    ap.add_argument(\"--csv\", required=True, help=\"Path to Advisor CSV export\")\n    ap.add_argument(\"--out\", required=True, help=\"Path to output Markdown file\")\n    ap.add_argument(\"--include-portal-link\", default=True, action=argparse.BooleanOptionalAction, help=\"Include Azure Portal links in output\")\n    ap.add_argument(\"--exclude-attached\", default=True, action=argparse.BooleanOptionalAction, help=\"Exclude currently attached disks from the unattached list\")\n    args = ap.parse_args()\n\n    csv_path = args.csv\n    out_path = args.out\n    include_portal = args.include_portal_link\n    exclude_attached_flag = args.exclude_attached\n\n    if not os.path.isfile(csv_path):\n        print(f\"CSV not found: {csv_path}\", file=sys.stderr)\n        sys.exit(2)\n\n    # Read CSV and collect disk IDs\n    all_rows: List[Dict[str, str]] = []\n    with open(csv_path, newline=\"\", encoding=\"utf-8-sig\") as f:\n        rdr = csv.DictReader(f)\n        for row in rdr:\n            all_rows.append(row)\n\n    disk_ids: List[str] = []\n    for row in all_rows:\n        rid = extract_disk_id(row)\n        if rid:\n            disk_ids.append(rid.strip())\n\n    # Deduplicate while preserving order\n    seen = set()\n    unique_ids = []\n    for rid in disk_ids:\n        if rid not in seen:\n            seen.add(rid)\n            unique_ids.append(rid)\n\n    sub_map = parse_subscriptions()\n\n    unattached_rows: List[Dict[str, Any]] = []\n    excluded_rows: List[Dict[str, Any]] = []\n    errors: List[Tuple[str, str]] = []\n    resolved = 0\n\n    for rid in unique_ids:\n        disk, err = get_disk(rid)\n        if err or not disk:\n            errors.append((rid, err or \"unknown error\"))\n            continue\n        resolved += 1\n        props = disk.get(\"properties\") or {}\n        name = disk.get(\"name\") or \"\"\n        location = disk.get(\"location\") or \"\"\n        sku = (disk.get(\"sku\") or {}).get(\"name\") or \"-\"\n        size_gb = props.get(\"diskSizeGb\") or props.get(\"diskSizeGB\") or \"-\"\n        os_type = props.get(\"osType\") or \"-\"\n        state = props.get(\"diskState\") or \"-\"\n        tags = disk.get(\"tags\") or {}\n        sub_id = None\n        rg = None\n        try:\n            # parse from id segments\n            parts = [p for p in (disk.get(\"id\") or rid).split(\"/\") if p]\n            # parts = [\"subscriptions\", sid, \"resourceGroups\", rg, \"providers\", \"Microsoft.Compute\", \"disks\", name]\n            if \"subscriptions\" in parts:\n                sub_id = parts[parts.index(\"subscriptions\")+1]\n            if \"resourceGroups\" in parts:\n                rg = parts[parts.index(\"resourceGroups\")+1]\n        except Exception:\n            pass\n        sub_name = sub_map.get(sub_id or \"\", sub_id or \"\")\n\n        row = {\n            \"name\": name,\n            \"resourceId\": disk.get(\"id\") or rid,\n            \"subscriptionId\": sub_id or \"\",\n            \"subscriptionName\": sub_name or \"\",\n            \"resourceGroup\": rg or \"\",\n            \"location\": location,\n            \"sku\": sku,\n            \"sizeGb\": size_gb,\n            \"osType\": os_type,\n            \"state\": state,\n            \"tags\": tags,\n            \"tagsHuman\": human_tags(tags),\n        }\n        if include_portal:\n            row[\"portalLink\"] = portal_link(row[\"resourceId\"])\n\n        if is_attached(disk):\n            if exclude_attached_flag:\n                row[\"excludeReason\"] = \"currently attached\"\n                excluded_rows.append(row)\n            else:\n                unattached_rows.append(row)  # user opted not to exclude\n        else:\n            unattached_rows.append(row)\n\n    title = f\"Unattached Disks Report - {dt.date.today().isoformat()}\"\n    generated_at = now_iso()\n    md = build_markdown(\n        title=title,\n        csv_path=csv_path,\n        generated_at=generated_at,\n        summary={\n            \"csv_rows\": len(all_rows),\n            \"unique_ids\": len(unique_ids),\n            \"resolved\": resolved\n        },\n        unattached_rows=unattached_rows,\n        excluded_rows=excluded_rows,\n        errors=errors\n    )\n\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(md)\n    print(f\"Wrote: {out_path}\")\n\nif __name__ == \"__main__\":\n    main()\n","language":"py","time":"11 days ago","created":"2025-11-13T12:11:24.408Z","annotations":[],"updated":"2025-11-19T14:20:08.895Z"},{"title":"Rolling Upgrade for Azure Kubernetes Service","id":"dbc836f7-74d2-408c-b10f-f8801d16761b","type":"CODE","raw":"az aks nodepool upgrade \\\n  --resource-group rg-ff-uks-gp-net \\\n  --cluster-name aks-ff-uks-gp-01 \\\n  --name system \\\n  --node-image-only\n\n","language":"sh","time":"4 months ago","created":"2025-08-05T10:20:17.580Z","annotations":[],"updated":"2025-08-12T16:30:38.822Z"},{"title":"Deployment Generator with Configurations and Output","id":"cff71cac-4e19-4bc8-b43a-e7ef16684ddc","type":"CODE","raw":"#!/bin/bash\n# tools/deployment-generator/generate.sh\n\nDEPLOYMENT_NAME=$1\n\n# Read enabled components\nENABLED_COMPONENTS=$(yq '.[]' deployments/$DEPLOYMENT_NAME/enabled-components.yaml)\n\n# Generate ffnode values.yaml\necho \"# Generated deployment configuration for $DEPLOYMENT_NAME\" > /tmp/generated-values.yaml\n\n# Merge component configurations\nfor component in $ENABLED_COMPONENTS; do\n    # Merge default values\n    yq eval-all 'select(fileIndex == 0) * select(fileIndex == 1)' \\\n        /tmp/generated-values.yaml \\\n        components/$component/default-values.yaml > /tmp/merged.yaml\n    \n    # Apply deployment-specific overrides if they exist\n    if [[ -f \"deployments/$DEPLOYMENT_NAME/component-overrides/$component.yaml\" ]]; then\n        yq eval-all 'select(fileIndex == 0) * select(fileIndex == 1)' \\\n            /tmp/merged.yaml \\\n            deployments/$DEPLOYMENT_NAME/component-overrides/$component.yaml > /tmp/final.yaml\n        mv /tmp/final.yaml /tmp/merged.yaml\n    fi\n    \n    mv /tmp/merged.yaml /tmp/generated-values.yaml\ndone\n\n# Output final configuration\nmv /tmp/generated-values.yaml deployments/$DEPLOYMENT_NAME/generated-values.yaml\necho \"Generated deployment configuration: deployments/$DEPLOYMENT_NAME/generated-values.yaml\"\n","language":"sh","time":"3 months ago","created":"2025-09-07T15:41:05.921Z","annotations":[],"updated":"2025-11-01T14:50:52.845Z"},{"title":"Cleanup Azure Snapshots","id":"53e28ce1-e346-438c-923c-7226983d5b9e","type":"CODE","raw":"#!/usr/bin/env bash\nset -euo pipefail\n\n# cleanup_azure_snapshots.sh\n# Requirements: az (Azure CLI), jq\n# Login first: az login (and set correct subscription if needed)\n\nKEEP_LATEST=3            # keep newest N snapshots per source disk\nMIN_AGE_DAYS=30          # only delete snapshots older than this (days)\nDELETE_ORPHANED=1        # delete snapshots whose source disk no longer exists (1=yes, 0=no)\nDRY_RUN=1                # 1=dry-run (print only), 0=execute deletes\nSUBSCRIPTION=\"\"          # e.g. \"00000000-0000-0000-0000-000000000000\"\nRESOURCE_GROUPS=\"\"       # comma-separated; if empty, all RGs in subscription\nPROTECT_TAG=\"\"           # e.g. \"keep=true\" or \"keep\" (any value)\nNAME_INCLUDE=\"\"          # regex; only consider names matching this\nNAME_EXCLUDE=\"\"          # regex; skip names matching this\n\nusage() {\n  cat <<EOF\nUsage: $0 [options]\n\nOptions:\n  --keep-latest N          Keep newest N per source disk (default: $KEEP_LATEST)\n  --min-age-days D         Only delete if older than D days (default: $MIN_AGE_DAYS)\n  --delete-orphaned 0|1    Delete snapshots whose source disk is missing (default: $DELETE_ORPHANED)\n  --dry-run 0|1            Print actions instead of deleting (default: $DRY_RUN)\n  --subscription ID        Azure subscription ID/name (optional)\n  --resource-groups CSV    Comma-separated resource groups; default = all in subscription\n  --protect-tag TAG[=VAL]  Keep snapshots with tag; VAL optional (protects any value)\n  --name-include REGEX     Only consider snapshots with names matching REGEX\n  --name-exclude REGEX     Exclude snapshots with names matching REGEX\n  -h, --help               Show help\n\nExamples:\n  $0 --dry-run 1 --min-age-days 60 --keep-latest 5\n  $0 --resource-groups rg1,rg2 --delete-orphaned 1 --protect-tag keep=true\n  $0 --name-exclude '^prod-' --keep-latest 2 --min-age-days 14 --dry-run 1\nEOF\n}\n\n# Parse args\nwhile [[ $# -gt 0 ]]; do\n  case \"$1\" in\n    --keep-latest) KEEP_LATEST=\"${2:-}\"; shift 2 ;;\n    --min-age-days) MIN_AGE_DAYS=\"${2:-}\"; shift 2 ;;\n    --delete-orphaned) DELETE_ORPHANED=\"${2:-}\"; shift 2 ;;\n    --dry-run) DRY_RUN=\"${2:-}\"; shift 2 ;;\n    --subscription) SUBSCRIPTION=\"${2:-}\"; shift 2 ;;\n    --resource-groups) RESOURCE_GROUPS=\"${2:-}\"; shift 2 ;;\n    --protect-tag) PROTECT_TAG=\"${2:-}\"; shift 2 ;;\n    --name-include) NAME_INCLUDE=\"${2:-}\"; shift 2 ;;\n    --name-exclude) NAME_EXCLUDE=\"${2:-}\"; shift 2 ;;\n    -h|--help) usage; exit 0 ;;\n    *) echo \"Unknown option: $1\"; usage; exit 1 ;;\n  esac\ndone\n\ncommand -v az >/dev/null 2>&1 || { echo \"ERROR: az CLI not found\"; exit 1; }\ncommand -v jq >/dev/null 2>&1 || { echo \"ERROR: jq not found\"; exit 1; }\n\nAZ_SUB_FLAG=()\n[[ -n \"$SUBSCRIPTION\" ]] && AZ_SUB_FLAG=(--subscription \"$SUBSCRIPTION\")\n\n# Verify login/subscription\naz account show \"${AZ_SUB_FLAG[@]}\" >/dev/null || { echo \"ERROR: run 'az login' and/or set subscription\"; exit 1; }\n\n# Build snapshots JSON\necho \"Fetching snapshots...\"\nSNAPS_JSON=\"[]\"\nif [[ -n \"$RESOURCE_GROUPS\" ]]; then\n  IFS=',' read -r -a RGS <<< \"$RESOURCE_GROUPS\"\n  for RG in \"${RGS[@]}\"; do\n    CHUNK=\"$(az snapshot list \"${AZ_SUB_FLAG[@]}\" --resource-group \"$RG\" -o json)\"\n    SNAPS_JSON=\"$(jq -s 'add' <(echo \"$SNAPS_JSON\") <(echo \"$CHUNK\"))\"\n  done\nelse\n  SNAPS_JSON=\"$(az snapshot list \"${AZ_SUB_FLAG[@]}\" -o json)\"\nfi\n\nTOTAL_SNAPS=\"$(echo \"$SNAPS_JSON\" | jq 'length')\"\necho \"Total snapshots found: $TOTAL_SNAPS\"\n\n# Fetch all disks to detect orphaned snapshots\necho \"Fetching disks to detect orphaned snapshots...\"\nDISKS_JSON=\"[]\"\nif [[ -n \"$RESOURCE_GROUPS\" ]]; then\n  DISKS_JSON=\"[]\"\n  for RG in \"${RGS[@]}\"; do\n    DCHUNK=\"$(az disk list \"${AZ_SUB_FLAG[@]}\" --resource-group \"$RG\" -o json)\"\n    DISKS_JSON=\"$(jq -s 'add' <(echo \"$DISKS_JSON\") <(echo \"$DCHUNK\"))\"\n  done\nelse\n  DISKS_JSON=\"$(az disk list \"${AZ_SUB_FLAG[@]}\" -o json)\"\nfi\nDISK_IDS=\"$(echo \"$DISKS_JSON\" | jq '[.[].id]')\"\n\n# Compute cutoff epoch for age filtering\nCUTOFF_EPOCH=\"$(date -u -v-\"$MIN_AGE_DAYS\"d +%s 2>/dev/null || true)\"\nif [[ -z \"$CUTOFF_EPOCH\" ]]; then\n  # Fallback for non-mac date (GNU coreutils)\n  CUTOFF_EPOCH=\"$(date -u -d \"$MIN_AGE_DAYS days ago\" +%s)\"\nfi\n\n# Split protect tag key/value\nPROTECT_KEY=\"\"\nPROTECT_VAL=\"\"\nif [[ -n \"$PROTECT_TAG\" ]]; then\n  if [[ \"$PROTECT_TAG\" == *\"=\"* ]]; then\n    PROTECT_KEY=\"${PROTECT_TAG%%=*}\"\n    PROTECT_VAL=\"${PROTECT_TAG#*=}\"\n  else\n    PROTECT_KEY=\"$PROTECT_TAG\"\n    PROTECT_VAL=\"\"\n  fi\nfi\n\n# Prepare filters into jq\nJQ_SCRIPT='\n  def norm(v): (v // empty);\n  def has_disk($ids; s): (s != null) and ($ids | index(s));\n  def ranked($keep):\n    group_by(.sourceDisk // \"none\")\n    | map(sort_by(.timeCreated | fromdateiso8601) | reverse\n          | to_entries | map(.value + {rank: .key}))\n    | add;\n\n  . as $snaps\n  | ($diskIds) as $diskIds\n  | ($keep_latest|tonumber) as $keep\n  | ($cutoff_epoch|tonumber) as $cutoff\n  | ($delete_orphaned|tonumber) as $del_orph\n  | ($protect_key) as $pkey\n  | ($protect_val) as $pval\n  | ($name_include) as $inc\n  | ($name_exclude) as $exc\n  | $snaps\n  | map(. + {\n      sourceDisk: .creationData.sourceResourceId,\n      timeEpoch: (.timeCreated | fromdateiso8601),\n      hasSource: has_disk($diskIds; .creationData.sourceResourceId),\n      protectedByTag: (\n        ($pkey|length) > 0 and (\n          ( .tags?[$pkey] != null and (($pval|length)==0 or .tags?[$pkey]==$pval) )\n        )\n      ),\n      includeName: ( ($inc|length)==0 or (.name | test($inc)) ),\n      excludeName: ( ($exc|length)>0 and (.name | test($exc)) )\n    })\n  | ranked($keep)\n  | map(. + {\n      deleteReason:\n        ( if (.protectedByTag or .excludeName or (not .includeName)) then \"skip:protected-or-filtered\"\n          elif ($del_orph==1 and (not .hasSource)) then \"delete:orphaned\"\n          elif (.rank >= $keep and .timeEpoch <= $cutoff) then \"delete:older-than-cutoff-and-beyond-keep\"\n          else \"keep\"\n          end )\n    })\n'\n\nFILTERED=\"$(jq \\\n  --argjson diskIds \"$DISK_IDS\" \\\n  --arg keep_latest \"$KEEP_LATEST\" \\\n  --arg cutoff_epoch \"$CUTOFF_EPOCH\" \\\n  --arg delete_orphaned \"$DELETE_ORPHANED\" \\\n  --arg protect_key \"$PROTECT_KEY\" \\\n  --arg protect_val \"$PROTECT_VAL\" \\\n  --arg name_include \"$NAME_INCLUDE\" \\\n  --arg name_exclude \"$NAME_EXCLUDE\" \\\n  \"$JQ_SCRIPT\" <<<\"$SNAPS_JSON\")\"\n\n# Report summary\nTO_DELETE=\"$(echo \"$FILTERED\" | jq '[.[] | select(.deleteReason|startswith(\"delete:\"))]')\"\nDELETE_COUNT=\"$(echo \"$TO_DELETE\" | jq 'length')\"\nORPH_COUNT=\"$(echo \"$FILTERED\" | jq '[.[] | select(.deleteReason==\"delete:orphaned\")] | length')\"\nAGE_COUNT=\"$(echo \"$FILTERED\" | jq '[.[] | select(.deleteReason==\"delete:older-than-cutoff-and-beyond-keep\")] | length')\"\nKEPT_COUNT=\"$(echo \"$FILTERED\" | jq '[.[] | select(.deleteReason==\"keep\" or .deleteReason==\"skip:protected-or-filtered\")] | length')\"\n\necho \"------------- Plan -------------\"\necho \"Keep-latest per disk: $KEEP_LATEST\"\necho \"Min age days: $MIN_AGE_DAYS (cutoff epoch $CUTOFF_EPOCH)\"\necho \"Delete orphaned: $DELETE_ORPHANED\"\n[[ -n \"$PROTECT_KEY\" ]] && echo \"Protect tag: $PROTECT_KEY=${PROTECT_VAL:-*}\"\n[[ -n \"$NAME_INCLUDE\" ]] && echo \"Name include: $NAME_INCLUDE\"\n[[ -n \"$NAME_EXCLUDE\" ]] && echo \"Name exclude: $NAME_EXCLUDE\"\necho \"Snapshots total: $TOTAL_SNAPS\"\necho \"Will delete: $DELETE_COUNT (orphaned: $ORPH_COUNT, aged: $AGE_COUNT); keep/skip: $KEPT_COUNT\"\necho \"--------------------------------\"\n\n# Print table of planned deletions\necho\necho \"Planned deletions:\"\necho \"$TO_DELETE\" | jq -r '.[] | [.resourceGroup, .name, (.diskSizeGb|tostring), .timeCreated, ( .sourceDisk // \"-\" ), .deleteReason] | @tsv' \\\n  | awk 'BEGIN{OFS=\"\\t\"; print \"ResourceGroup\",\"Name\",\"SizeGB\",\"Created\",\"SourceDisk\",\"Reason\"}1'\n\nif [[ \"$DRY_RUN\" -eq 1 ]]; then\n  echo\n  echo \"[DRY-RUN] No deletions performed. Re-run with --dry-run 0 to apply.\"\n  exit 0\nfi\n\necho\necho \"Proceeding to delete $DELETE_COUNT snapshots...\"\n# Delete in batches\necho \"$TO_DELETE\" | jq -r '.[].id' | while IFS= read -r SNAP_ID; do\n  echo \"Deleting: $SNAP_ID\"\n  az snapshot delete \"${AZ_SUB_FLAG[@]}\" --ids \"$SNAP_ID\" --no-wait || {\n    echo \"WARN: delete failed for $SNAP_ID (locked or permission issue?)\"\n  }\ndone\n\necho \"Delete requests submitted. You can monitor with:\"\necho \"  az snapshot list ${SUBSCRIPTION:+--subscription \\\"$SUBSCRIPTION\\\"} -o table\"","language":"sh","time":"11 days ago","created":"2025-11-13T14:11:48.626Z","annotations":[],"updated":"2025-11-13T14:19:29.756Z"},{"title":"FitFile Repository List and Show Tags","id":"eac7d0ae-3bf3-4b7e-9537-932797d19499","type":"CODE","raw":"az acr repository list --name fitfileregistry --output json | jq -r '.[]' | while read repo; do\n  echo \"Repository: $repo\"\n  az acr repository show-tags --name fitfileregistry --repository \"$repo\" --output table\n  echo \"\"\ndone\n","language":"sh","time":"3 months ago","created":"2025-09-09T12:38:10.368Z","annotations":[],"updated":"2025-11-08T12:10:23.129Z"},{"title":"Cluster Identity and Backup Contributor Role Creation","id":"6669a23a-b8cd-4b2a-99be-8a387924050a","type":"CODE","raw":"# Get the cluster identity principal ID\nCLUSTER_ID=$(az aks show --resource-group fitfile-cloud-staging-rg --name fitfile-cloud-staging-aks-cluster --query identity.principalId -o tsv)\necho \"Cluster Identity: $CLUSTER_ID\"\n\n# Get the backup vault resource ID  \nVAULT_ID=$(az resource show --ids \"/subscriptions/249df46b-f75d-4492-8e78-b33a00473548/resourceGroups/staging-backup-rg/providers/Microsoft.DataProtection/backupVaults/aksbackupvault\" --query id -o tsv)\necho \"Backup Vault ID: $VAULT_ID\"\n\n# Grant the Backup Contributor role\naz role assignment create \\\n  --assignee \"$CLUSTER_ID\" \\\n  --role \"Backup Contributor\" \\\n  --scope \"$VAULT_ID\"\n\n# Verify the role assignment was created\naz role assignment list \\\n  --assignee \"$CLUSTER_ID\" \\\n  --scope \"$VAULT_ID\" \\\n  --query '[].{role:roleDefinitionName}' \\\n  -o table","language":"sh","time":"11 days ago","created":"2025-11-13T14:36:26.015Z","annotations":[],"updated":"2025-11-19T11:50:21.097Z"},{"title":"EKS Node Egress Troubleshooting Script","id":"99616a61-aab2-4a37-8082-deb3cdda28ad","type":"CODE","raw":"#!/bin/bash\n\n# EKS Node Egress Troubleshooting Script\n# This script diagnoses outbound connectivity issues from an EKS worker node,\n# which is the root cause of ImagePullBackOff errors when nodes cannot reach\n# an external container registry.\n\nset -eo pipefail\n\n# --- Configuration ---\n# Details from the problem description and logs\nCLUSTER_NAME=\"hie-prod-34\"\nREGION=\"eu-west-2\"\nAPP_LABEL_SELECTOR=\"app.kubernetes.io/name=relay\"\nRELAY_NAMESPACE=\"hutch\"\nHTTPS_PORT=\"443\"\n\n# --- Script Colours ---\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nCYAN='\\033[0;36m'\nNC='\\033[0m' # No Colour\n\necho -e \"${GREEN}ðŸ” EKS Node Egress Troubleshooting for Cluster '${CLUSTER_NAME}'${NC}\"\necho \"==========================================================\"\n\n# Function to check if a command exists\ncommand_exists() {\n    command -v \"$1\" >/dev/null 2>&1\n}\n\n# --- Prerequisite Checks ---\ncheck_prerequisites() {\n    echo \"ðŸ” Checking for required tools (aws, kubectl, jq)...\"\n    if ! command_exists aws; then\n        echo -e \"${RED}âŒ AWS CLI is not installed. Please install it to continue.${NC}\"\n        exit 1\n    fi\n    if ! command_exists kubectl; then\n        echo -e \"${RED}âŒ kubectl is not installed. Please install it to continue.${NC}\"\n        exit 1\n    fi\n    if ! command_exists jq; then\n        echo -e \"${RED}âŒ jq is not installed. Please install it to continue.${NC}\"\n        exit 1\n    fi\n\n    if ! aws sts get-caller-identity >/dev/null 2>&1; then\n        echo -e \"${RED}âŒ AWS CLI not configured or credentials invalid. Run 'aws configure'.${NC}\"\n        exit 1\n    fi\n    echo -e \"${GREEN}âœ… AWS CLI is configured.${NC}\"\n\n    if ! kubectl cluster-info >/dev/null 2>&1; then\n        echo -e \"${YELLOW}âš ï¸  kubectl not configured. Attempting to configure...${NC}\"\n        aws eks update-kubeconfig --region ${REGION} --name ${CLUSTER_NAME}\n        if ! kubectl cluster-info >/dev/null 2>&1; then\n            echo -e \"${RED}âŒ Failed to configure kubectl for cluster ${CLUSTER_NAME}.${NC}\"\n            exit 1\n        fi\n    fi\n    echo -e \"${GREEN}âœ… kubectl is configured for cluster '${CLUSTER_NAME}'.${NC}\"\n}\n\n# --- Main Diagnostic Function ---\nrun_diagnostics() {\n    # --- Pod and Node Identification ---\n    echo -e \"\\n--- Identifying Failing Pod and Node ---\"\n    POD_JSON=$(kubectl get pods -n \"${RELAY_NAMESPACE}\" -l \"${APP_LABEL_SELECTOR}\" -o json)\n    \n    if [[ $(echo \"$POD_JSON\" | jq '.items | length') -eq 0 ]]; then\n        echo -e \"${RED}âŒ No pods found with label '${APP_LABEL_SELECTOR}' in namespace '${RELAY_NAMESPACE}'. Aborting.${NC}\"\n        return 1\n    fi\n\n    POD_NAME=$(echo \"$POD_JSON\" | jq -r '.items[0].metadata.name')\n    NODE_NAME=$(echo \"$POD_JSON\" | jq -r '.items[0].spec.nodeName')\n    \n    echo \"âœ… Found Pod: ${POD_NAME}\"\n    echo \"âœ… Pod is scheduled on Node: ${NODE_NAME}\"\n\n    # --- EC2 Instance and Network Details ---\n    echo -e \"\\n--- Fetching EC2 and VPC Details ---\"\n    INSTANCE_ID=$(aws ec2 describe-instances --region \"${REGION}\" --filters \"Name=private-dns-name,Values=${NODE_NAME}\" --query \"Reservations[0].Instances[0].InstanceId\" --output text)\n    if [[ -z \"$INSTANCE_ID\" || \"$INSTANCE_ID\" == \"None\" ]]; then\n        echo -e \"${RED}âŒ Could not find EC2 instance for node '${NODE_NAME}'.${NC}\"\n        return 1\n    fi\n    \n    INSTANCE_DETAILS=$(aws ec2 describe-instances --instance-ids \"${INSTANCE_ID}\" --region \"${REGION}\" --query \"Reservations[0].Instances[0]\")\n    SUBNET_ID=$(echo \"$INSTANCE_DETAILS\" | jq -r '.SubnetId')\n    VPC_ID=$(echo \"$INSTANCE_DETAILS\" | jq -r '.VpcId')\n    SG_ID=$(echo \"$INSTANCE_DETAILS\" | jq -r '.SecurityGroups[0].GroupId')\n\n    echo \"âœ… Instance ID: ${INSTANCE_ID}\"\n    echo \"âœ… VPC ID: ${VPC_ID}\"\n    echo \"âœ… Subnet ID: ${SUBNET_ID}\"\n    echo \"âœ… Security Group ID: ${SG_ID}\"\n\n    # --- Route Table Analysis ---\n    echo -e \"\\n--- Analysing Route Table for Subnet ${SUBNET_ID} ---\"\n    ROUTE_TABLE_ID=$(aws ec2 describe-route-tables --region \"${REGION}\" --filters \"Name=association.subnet-id,Values=${SUBNET_ID}\" --query \"RouteTables[0].RouteTableId\" --output text)\n    echo \"ðŸ” Subnet is associated with Route Table: ${ROUTE_TABLE_ID}\"\n    aws ec2 describe-route-tables --route-table-ids \"${ROUTE_TABLE_ID}\" --region \"${REGION}\" | jq -r '.RouteTables[0].Routes[] | \"  - Dest: \\(.DestinationCidrBlock // .DestinationPrefixListId // \"N/A\"), Target: \\(.GatewayId // .NatGatewayId // .TransitGatewayId // \"N/A\"), State: \\(.State)\"'\n\n    DEFAULT_ROUTE_TARGET=$(aws ec2 describe-route-tables --route-table-ids \"${ROUTE_TABLE_ID}\" --region \"${REGION}\" --query \"RouteTables[0].Routes[?DestinationCidrBlock=='0.0.0.0/0'] | [0]\")\n    \n    if [[ -z \"$DEFAULT_ROUTE_TARGET\" || \"$DEFAULT_ROUTE_TARGET\" == \"null\" ]]; then\n        echo -e \"${RED}âŒ [FAIL] No default route (0.0.0.0/0) found in the route table. This is the primary cause of no internet access.${NC}\"\n        ROUTE_OK=1\n    elif [[ $(echo \"$DEFAULT_ROUTE_TARGET\" | jq -r '.NatGatewayId') != \"null\" ]]; then\n        echo -e \"${GREEN}âœ… [PASS] Default route points to a NAT Gateway.\"\n    elif [[ $(echo \"$DEFAULT_ROUTE_TARGET\" | jq -r '.GatewayId') != \"null\" ]]; then\n        echo -e \"${GREEN}âœ… [PASS] Default route points to an Internet Gateway.\"\n    else\n        echo -e \"${RED}âŒ [FAIL] Default route (0.0.0.0/0) does not point to a NAT Gateway or an Internet Gateway.${NC}\"\n        ROUTE_OK=1\n    fi\n\n    # --- Security Group Egress Analysis ---\n    echo -e \"\\n--- Analysing OUTBOUND Rules for Security Group ${SG_ID} ---\"\n    aws ec2 describe-security-groups --group-ids \"${SG_ID}\" --region \"${REGION}\" | jq -r '.SecurityGroups[0].IpPermissionsEgress[] | \"  - Protocol: \\(.IpProtocol), Port: \\(.FromPort // \"All\")-\\(.ToPort // \"All\"), Dest: \\(.IpRanges[0].CidrIp // .PrefixListIds[0].PrefixListId // \"N/A\")\"'\n    \n    HTTPS_EGRESS_EXISTS=$(aws ec2 describe-security-groups --group-ids \"${SG_ID}\" --region \"${REGION}\" --query \"SecurityGroups[0].IpPermissionsEgress[?IpProtocol=='tcp' && FromPort<=\\`${HTTPS_PORT}\\` && ToPort>=\\`${HTTPS_PORT}\\` && IpRanges[?CidrIp=='0.0.0.0/0']] | length(@)\")\n    if [[ \"$HTTPS_EGRESS_EXISTS\" -eq 0 ]]; then\n        echo -e \"${RED}âŒ [FAIL] No outbound rule found allowing TCP traffic on port ${HTTPS_PORT} to 0.0.0.0/0.${NC}\"\n        SG_OK=1\n    else\n        echo -e \"${GREEN}âœ… [PASS] Security group allows outbound HTTPS traffic to the internet.${NC}\"\n    fi\n\n    # --- Network ACL Analysis ---\n    echo -e \"\\n--- Analysing Network ACL for Subnet ${SUBNET_ID} ---\"\n    NACL_ID=$(aws ec2 describe-network-acls --filters \"Name=association.subnet-id,Values=${SUBNET_ID}\" --query 'NetworkAcls[0].NetworkAclId' --output text)\n    echo \"ðŸ” Subnet is associated with NACL: ${NACL_ID}\"\n    echo -e \"${CYAN}  Outbound Rules:${NC}\"\n    aws ec2 describe-network-acls --network-acl-id \"${NACL_ID}\" --region \"${REGION}\" | jq -r '.NetworkAcls[0].Entries[] | select(.Egress == true) | \"    - Rule \\(.RuleNumber): \\(.RuleAction) \\(.Protocol) Port \\(.PortRange.From // \"All\")-\\(.PortRange.To // \"All\") Dest \\(.CidrBlock)\"'\n    echo -e \"${CYAN}  Inbound Rules (for return traffic):${NC}\"\n    aws ec2 describe-network-acls --network-acl-id \"${NACL_ID}\" --region \"${REGION}\" | jq -r '.NetworkAcls[0].Entries[] | select(.Egress == false) | \"    - Rule \\(.RuleNumber): \\(.RuleAction) \\(.Protocol) Port \\(.PortRange.From // \"All\")-\\(.PortRange.To // \"All\") Source \\(.CidrBlock)\"'\n    \n    # Check for specific deny rules that could block the connection\n    NACL_DENY_EGRESS=$(aws ec2 describe-network-acls --network-acl-ids \"${NACL_ID}\" --query \"NetworkAcls[0].Entries[?RuleAction=='deny' && PortRange.From <= \\`${HTTPS_PORT}\\` && PortRange.To >= \\`${HTTPS_PORT}\\` && Egress==\\`true\\`] | length(@)\")\n    NACL_DENY_INGRESS_EPHEMERAL=$(aws ec2 describe-network-acls --network-acl-ids \"${NACL_ID}\" --query \"NetworkAcls[0].Entries[?RuleAction=='deny' && PortRange.From <= \\`1024\\` && PortRange.To >= \\`65535\\` && Egress==\\`false\\`] | length(@)\")\n\n    if [[ \"$NACL_DENY_EGRESS\" -gt 0 ]]; then\n        echo -e \"${RED}âŒ [FAIL] NACL (${NACL_ID}) has a rule DENYING OUTBOUND traffic on port ${HTTPS_PORT}.${NC}\"\n        NACL_OK=1\n    elif [[ \"$NACL_DENY_INGRESS_EPHEMERAL\" -gt 0 ]]; then\n        echo -e \"${RED}âŒ [FAIL] NACL (${NACL_ID}) has a rule DENYING INBOUND traffic on the ephemeral ports (1024-65535), which could block return traffic.${NC}\"\n        NACL_OK=1\n    else\n        echo -e \"${GREEN}âœ… [PASS] NACL rules appear to allow the required outbound and return traffic.${NC}\"\n    fi\n}\n\n# --- Main Execution ---\nmain() {\n    check_prerequisites\n    ROUTE_OK=0; SG_OK=0; NACL_OK=0\n    run_diagnostics\n\n    echo -e \"\\n--- ðŸ“‹ Final Diagnosis & Recommendations ---\"\n    if [[ \"$ROUTE_OK\" -ne 0 ]]; then\n        echo -e \"${YELLOW}Primary Issue: The route table for the EKS worker subnet is missing a default route ('0.0.0.0/0') to an Internet Gateway or NAT Gateway.${NC}\"\n        echo \"Solution: Add a default route to the route table '${ROUTE_TABLE_ID}' that points to your VPC's NAT Gateway or Internet Gateway.\"\n    elif [[ \"$SG_OK\" -ne 0 ]]; then\n        echo -e \"${YELLOW}Primary Issue: The worker node's security group '${SG_ID}' is blocking outbound HTTPS traffic.${NC}\"\n        echo \"Solution: Add an outbound rule to '${SG_ID}' that allows TCP traffic on port 443 to destination 0.0.0.0/0.\"\n    elif [[ \"$NACL_OK\" -ne 0 ]]; then\n        echo -e \"${YELLOW}Primary Issue: The Network ACL '${NACL_ID}' is blocking the required traffic.${NC}\"\n        echo \"Solution: Review the outbound rules to ensure port 443 is allowed, and review the inbound rules to ensure the ephemeral return ports (1024-65535) are allowed.\"\n    else\n        echo -e \"${GREEN}âœ… All networking checks passed. The egress path from the node appears to be correctly configured. If image pulls are still failing, consider:\"\n        echo \"  1. DNS Resolution Issues within the VPC.\"\n        echo \"  2. Authentication issues with the Azure Container Registry (check 'imagePullSecrets').\"\n        echo \"  3. Temporary issues with the Azure Container Registry itself.\"\n    fi\n}\n\nmain \"$@\"\n","language":"sh","time":"about a month ago","created":"2025-09-25T12:02:47.435Z","annotations":[],"updated":"2025-09-26T09:32:27.784Z"},{"title":"Zellij Plugin Configuration and Keybinds","id":"478ee0b5-f052-49d7-b8dc-f707f2ef8627","type":"CODE","raw":"plugins {\n    tab-bar location=\"zellij:tab-bar\"\n    status-bar location=\"zellij:status-bar\"\n    strider location=\"zellij:strider\"\n    compact-bar location=\"zellij:compact-bar\"\n    session-manager location=\"zellij:session-manager\"\n    configuration location=\"zellij:configuration\"\n    plugin-manager location=\"zellij:plugin-manager\"\n    about location=\"zellij:about\"\n}\nload_plugins {\n}\n\n\nkeybinds {\n    unbind \"Ctrl g\"\n    unbind \"Ctrl q\"\n\n    normal {\n        bind \"Super \\[\" { GoToPreviousTab; }\n        bind \"Super \\]\" { GoToNextTab; }\n        bind \"Super 1\" { GoToTab 1; SwitchToMode \"Normal\"; }\n        bind \"Super 2\" { GoToTab 2; SwitchToMode \"Normal\"; }\n        bind \"Super 3\" { GoToTab 3; SwitchToMode \"Normal\"; }\n        bind \"Super 4\" { GoToTab 4; SwitchToMode \"Normal\"; }\n        bind \"Super 5\" { GoToTab 5; SwitchToMode \"Normal\"; }\n        bind \"Super 6\" { GoToTab 6; SwitchToMode \"Normal\"; }\n        bind \"Super 7\" { GoToTab 7; SwitchToMode \"Normal\"; }\n        bind \"Super 8\" { GoToTab 8; SwitchToMode \"Normal\"; }\n        bind \"Super 9\" { GoToTab 9; SwitchToMode \"Normal\"; }\n    }\n\n    locked {\n        bind \"Super g\" { SwitchToMode \"Normal\"; }\n    }\n\n    tab {\n      unbind \"s\"\n    }\n\n    tmux {\n        bind \"Ctrl b\" { DumpScreen \"/Users/towry/workspace/zellij-buffer.txt\"; SwitchToMode \"Normal\"; }\n        bind \"y\" {\n            Run \"yazi\" {\n                floating true\n                close_on_exit true\n                width \"80%\"\n                height \"80%\"\n                x \"10\"\n                y \"5%\"\n            }\n            SwitchToMode \"Normal\";\n        }\n    }\n\n    shared_except \"locked\" {\n        bind \"Super g\" { SwitchToMode \"Locked\"; }\n    }\n    shared_except \"locked\" \"normal\" {\n        bind \"Enter\" \"Esc\" { SwitchToMode \"Normal\"; }\n    }\n    shared_except \"pane\" \"locked\" {\n        unbind \"Ctrl p\"\n        bind \"Super p\" { SwitchToMode \"Pane\"; }\n    }\n    shared_except \"resize\" \"locked\" {\n        unbind \"Ctrl n\"\n        bind \"Super n\" { SwitchToMode \"Resize\"; }\n    }\n    shared_except \"scroll\" \"locked\" {\n        unbind \"Ctrl s\"\n        bind \"Super s\" { SwitchToMode \"Scroll\"; }\n    }\n    shared_except \"session\" \"locked\" {\n        unbind \"Ctrl o\"\n        bind \"Super o\" { SwitchToMode \"Session\"; }\n    }\n    shared_except \"tab\" \"locked\" {\n        unbind \"Ctrl t\"\n        bind \"Super t\" { SwitchToMode \"Tab\"; }\n    }\n    shared_except \"move\" \"locked\" {\n        unbind \"Ctrl h\"\n        bind \"Super k\" { SwitchToMode \"Move\"; }\n    }\n    shared_except \"tmux\" \"locked\" {\n        unbind \"Ctrl b\"\n        bind \"Ctrl z\" { SwitchToMode \"Tmux\"; }\n    }\n}\n\nui {\n    pane_frames {\n        hide_session_name false\n        rounded_corners false\n    }\n}\n\ndefault_mode \"normal\"\ncopy_command \"pbcopy\"\ncopy_clipboard \"system\"\nsupport_kitty_keyboard_protocol true\ncopy_on_select true\nshow_release_notes false\nstyled_underlines true\nshow_startup_tips true","language":"sh","time":"7 days ago","created":"2025-11-17T12:13:18.976Z","annotations":[],"updated":"2025-11-19T14:08:47.730Z"},{"title":"Allow Actions for ECR Access","id":"60931fdf-018e-4934-920f-fa03ccf8d42c","type":"CODE","raw":"{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ec2:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"eks:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"elasticloadbalancing:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ssm:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"route53:*\",\n                \"route53domains:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"acm:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kms:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"network-firewall:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ecr-public:GetAuthorizationToken\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}","language":"json","time":"about a month ago","created":"2025-10-09T11:46:45.696Z","annotations":[],"updated":"2025-11-01T15:01:32.063Z"},{"title":"Code Snippet: Configuration for Client and Manager","id":"3c91c770-1007-459e-9bfc-30328a874e7b","type":"CODE","raw":"{\n  \"cli_auth0_client_id\": \"\", // Leave blank - do not need to fill\n  \"cli_auth0_client_secret\": \"\", // Leave blank - do not need to fill\n\n  \"mesh_client_cert\": \"\", // Leave blank if optout not required\n  \"mesh_client_key\": \"\", // Leave blank if optout not required\n  \"mesh_hash_secret\": \"\", // Leave blank if optout not required\n  \"mesh_mailbox_password\": \"\", // Leave blank if optout not required\n\n  \"mongodb_password\": \"\", // generate secure password (e.g. from LastPass) (min length 10, alphanumeric only)\n  \"mongodb_username\": \"root\",\n  \"mongodb_replica_set_key\": \"\", // generate secure password (length: 64, alphanumeric only)\n\n  \"postgresql_password\": \"\", // generate secure password (e.g. from LastPass) (min length 10, alphanumeric only)\n  \"postgresql_username\": \"postgres\",\n\n  \"s3_access_key_id\": \"ffadmin\",\n  \"s3_secret_access_key\": \"\", // generate secure password (min length 10, alphanumeric only)\n\n  \"ude_key\": \"\", // generate from ude_cli using `key-gen` command. Needs to be same in all connected tenants\n\n  \"spicedb_pre_shared_key\": \"\" // This may be different based on whether you use centralised spicedb or not. If centralised, get it from vault from admin/fitfile/production/spicedb_secrets. Otherwise, get from spicedb_secrets you will create\n\n  \"fitfile_tenant_pkcs8.key\": \"\" // The private tenant pkcs8 signing key. See below\n  \"fitfile_tenant_public.crt\": \"\" // The public tenant signing key. See below\n}","language":"json","time":"5 days ago","created":"2025-11-19T11:08:48.008Z","annotations":[],"updated":"2025-11-19T11:50:08.813Z"},{"title":"Microsoft Network VNET Networks Configuration","id":"35c9a5fd-55e6-4cae-9ef0-dfe2635510a9","type":"CODE","raw":"{\n    \"apiVersion\": \"2024-07-01\",\n    \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/virtualNetworks/NNUHFT-SDE-vnet1\",\n    \"name\": \"NNUHFT-SDE-vnet1\",\n    \"type\": \"microsoft.network/virtualnetworks\",\n    \"location\": \"uksouth\",\n    \"tags\": {\n        \"Department\": \"SDE\",\n        \"Environment\": \"live\"\n    },\n    \"properties\": {\n        \"provisioningState\": \"Succeeded\",\n        \"resourceGuid\": \"b9f61864-7998-402c-ad0b-79958eb1884a\",\n        \"addressSpace\": {\n            \"addressPrefixes\": [\n                \"192.168.200.0/24\"\n            ]\n        },\n        \"encryption\": {\n            \"enabled\": false,\n            \"enforcement\": \"AllowUnencrypted\"\n        },\n        \"privateEndpointVNetPolicies\": \"Disabled\",\n        \"subnets\": [\n            {\n                \"name\": \"NAT\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/virtualNetworks/NNUHFT-SDE-vnet1/subnets/NAT\",\n                \"etag\": \"W/\\\"ce9c5acf-61a7-4eab-97a7-ff19937fb44e\\\"\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"addressPrefixes\": [\n                        \"192.168.200.0/29\"\n                    ],\n                    \"natGateway\": {\n                        \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/natGateways/NNUHFT-SDE-nat\"\n                    },\n                    \"delegations\": [],\n                    \"privateEndpointNetworkPolicies\": \"Disabled\",\n                    \"privateLinkServiceNetworkPolicies\": \"Enabled\",\n                    \"defaultOutboundAccess\": false\n                },\n                \"type\": \"Microsoft.Network/virtualNetworks/subnets\"\n            }\n        ],\n        \"virtualNetworkPeerings\": [\n            {\n                \"name\": \"NNUHFT-SDE-vnet1-to-NNUH-HUB-vnet1\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/virtualNetworks/NNUHFT-SDE-vnet1/virtualNetworkPeerings/NNUHFT-SDE-vnet1-to-NNUH-HUB-vnet1\",\n                \"etag\": \"W/\\\"ce9c5acf-61a7-4eab-97a7-ff19937fb44e\\\"\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"resourceGuid\": \"3310efdf-4766-0415-1f7d-64e36ccfc955\",\n                    \"peeringState\": \"Connected\",\n                    \"peeringSyncLevel\": \"FullyInSync\",\n                    \"remoteVirtualNetwork\": {\n                        \"id\": \"/subscriptions/e09cdc6e-501c-40f2-8333-4865f7911785/resourceGroups/NNUH-HUB-Networking/providers/Microsoft.Network/virtualNetworks/NNUH-HUB-vnet1\"\n                    },\n                    \"allowVirtualNetworkAccess\": true,\n                    \"allowForwardedTraffic\": true,\n                    \"allowGatewayTransit\": false,\n                    \"useRemoteGateways\": false,\n                    \"doNotVerifyRemoteGateways\": false,\n                    \"peerCompleteVnets\": true,\n                    \"remoteAddressSpace\": {\n                        \"addressPrefixes\": [\n                            \"192.168.208.0/20\"\n                        ]\n                    },\n                    \"remoteVirtualNetworkAddressSpace\": {\n                        \"addressPrefixes\": [\n                            \"192.168.208.0/20\"\n                        ]\n                    },\n                    \"routeServiceVips\": {}\n                },\n                \"type\": \"Microsoft.Network/virtualNetworks/virtualNetworkPeerings\"\n            }\n        ],\n        \"enableDdosProtection\": false\n    },\n    \"etag\": \"W/\\\"ce9c5acf-61a7-4eab-97a7-ff19937fb44e\\\"\"\n}","language":"json","time":"5 days ago","created":"2025-11-19T11:39:42.084Z","annotations":[],"updated":"2025-11-19T12:15:47.605Z"},{"title":"Microsoft Network Networks with Public IP and Subnets","id":"08714295-4248-461f-89df-7edfba1d37d5","type":"CODE","raw":"{\n    \"apiVersion\": \"2024-07-01\",\n    \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/natGateways/NNUHFT-SDE-nat\",\n    \"name\": \"NNUHFT-SDE-nat\",\n    \"type\": \"microsoft.network/natgateways\",\n    \"sku\": {\n        \"name\": \"Standard\",\n        \"tier\": \"Regional\"\n    },\n    \"location\": \"uksouth\",\n    \"tags\": {\n        \"Department\": \"SDE\",\n        \"Environment\": \"live\"\n    },\n    \"properties\": {\n        \"provisioningState\": \"Succeeded\",\n        \"resourceGuid\": \"5877b0da-bb57-4e37-a124-176e00971c56\",\n        \"idleTimeoutInMinutes\": 4,\n        \"scope\": \"Public\",\n        \"privateIPAddresses\": [],\n        \"privateIPAddressesV6\": [],\n        \"publicIpAddresses\": [\n            {\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/publicIPAddresses/NNUHFT-SDE-nat-ip\"\n            }\n        ],\n        \"subnets\": [\n            {\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/virtualNetworks/NNUHFT-SDE-vnet1/subnets/NAT\"\n            }\n        ]\n    },\n    \"etag\": \"W/\\\"42d48370-daf6-48a1-8852-c4fd69ce306d\\\"\"\n}","language":"json","time":"5 days ago","created":"2025-11-19T11:40:14.814Z","annotations":[],"updated":"2025-11-19T11:49:51.559Z"},{"title":"Microsoft Network Networks with VPC and Etag","id":"77aad0f8-1b8d-4308-9213-e6a006d6b925","type":"CODE","raw":"{\n    \"apiVersion\": \"2024-07-01\",\n    \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/publicIPAddresses/NNUHFT-SDE-nat-ip\",\n    \"name\": \"NNUHFT-SDE-nat-ip\",\n    \"type\": \"microsoft.network/publicipaddresses\",\n    \"sku\": {\n        \"name\": \"Standard\",\n        \"tier\": \"Regional\"\n    },\n    \"location\": \"uksouth\",\n    \"properties\": {\n        \"provisioningState\": \"Succeeded\",\n        \"resourceGuid\": \"bd2ff1e4-64db-44b7-bcf9-8c20fb10eae3\",\n        \"natGateway\": {\n            \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/natGateways/NNUHFT-SDE-nat\"\n        },\n        \"ipAddress\": \"20.162.236.86\",\n        \"publicIPAddressVersion\": \"IPv4\",\n        \"publicIPAllocationMethod\": \"Static\",\n        \"idleTimeoutInMinutes\": 4,\n        \"ipTags\": [],\n        \"ddosSettings\": {\n            \"protectionMode\": \"VirtualNetworkInherited\"\n        }\n    },\n    \"etag\": \"W/\\\"6fe40af2-f6fb-436f-a3cf-eb1fabd4b4bb\\\"\"\n}","language":"json","time":"5 days ago","created":"2025-11-19T11:40:36.741Z","annotations":[],"updated":"2025-11-19T11:49:57.684Z"},{"title":"Microsoft Network Networks with VPC and Etag","id":"995ea175-63f1-4dfb-b05e-8c4b062b776f","type":"CODE","raw":"{\n    \"apiVersion\": \"2024-07-01\",\n    \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/publicIPAddresses/NNUHFT-SDE-nat-ip\",\n    \"name\": \"NNUHFT-SDE-nat-ip\",\n    \"type\": \"microsoft.network/publicipaddresses\",\n    \"sku\": {\n        \"name\": \"Standard\",\n        \"tier\": \"Regional\"\n    },\n    \"location\": \"uksouth\",\n    \"properties\": {\n        \"provisioningState\": \"Succeeded\",\n        \"resourceGuid\": \"bd2ff1e4-64db-44b7-bcf9-8c20fb10eae3\",\n        \"natGateway\": {\n            \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/natGateways/NNUHFT-SDE-nat\"\n        },\n        \"ipAddress\": \"20.162.236.86\",\n        \"publicIPAddressVersion\": \"IPv4\",\n        \"publicIPAllocationMethod\": \"Static\",\n        \"idleTimeoutInMinutes\": 4,\n        \"ipTags\": [],\n        \"ddosSettings\": {\n            \"protectionMode\": \"VirtualNetworkInherited\"\n        }\n    },\n    \"etag\": \"W/\\\"6fe40af2-f6fb-436f-a3cf-eb1fabd4b4bb\\\"\"\n}","language":"json","time":"5 days ago","created":"2025-11-19T11:40:37.285Z","annotations":[],"updated":"2025-11-19T12:07:53.044Z"},{"title":"Allow inbound traffic from VMs in VNET","id":"4a90b29d-4642-4ae6-9e35-db1c7ee51128","type":"CODE","raw":"{\n    \"apiVersion\": \"2024-07-01\",\n    \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg\",\n    \"name\": \"NNUHFT-SDE-nsg\",\n    \"type\": \"microsoft.network/networksecuritygroups\",\n    \"location\": \"uksouth\",\n    \"tags\": {\n        \"Department\": \"SDE\",\n        \"Environment\": \"live\"\n    },\n    \"properties\": {\n        \"provisioningState\": \"Succeeded\",\n        \"resourceGuid\": \"c002268e-397b-4d27-aff7-d6a18c86d09e\",\n        \"securityRules\": [],\n        \"defaultSecurityRules\": [\n            {\n                \"name\": \"AllowVnetInBound\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg/defaultSecurityRules/AllowVnetInBound\",\n                \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\",\n                \"type\": \"Microsoft.Network/networkSecurityGroups/defaultSecurityRules\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"description\": \"Allow inbound traffic from all VMs in VNET\",\n                    \"protocol\": \"*\",\n                    \"sourcePortRange\": \"*\",\n                    \"destinationPortRange\": \"*\",\n                    \"sourceAddressPrefix\": \"VirtualNetwork\",\n                    \"destinationAddressPrefix\": \"VirtualNetwork\",\n                    \"access\": \"Allow\",\n                    \"priority\": 65000,\n                    \"direction\": \"Inbound\",\n                    \"sourcePortRanges\": [],\n                    \"destinationPortRanges\": [],\n                    \"sourceAddressPrefixes\": [],\n                    \"destinationAddressPrefixes\": []\n                }\n            },\n            {\n                \"name\": \"AllowAzureLoadBalancerInBound\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg/defaultSecurityRules/AllowAzureLoadBalancerInBound\",\n                \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\",\n                \"type\": \"Microsoft.Network/networkSecurityGroups/defaultSecurityRules\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"description\": \"Allow inbound traffic from azure load balancer\",\n                    \"protocol\": \"*\",\n                    \"sourcePortRange\": \"*\",\n                    \"destinationPortRange\": \"*\",\n                    \"sourceAddressPrefix\": \"AzureLoadBalancer\",\n                    \"destinationAddressPrefix\": \"*\",\n                    \"access\": \"Allow\",\n                    \"priority\": 65001,\n                    \"direction\": \"Inbound\",\n                    \"sourcePortRanges\": [],\n                    \"destinationPortRanges\": [],\n                    \"sourceAddressPrefixes\": [],\n                    \"destinationAddressPrefixes\": []\n                }\n            },\n            {\n                \"name\": \"DenyAllInBound\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg/defaultSecurityRules/DenyAllInBound\",\n                \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\",\n                \"type\": \"Microsoft.Network/networkSecurityGroups/defaultSecurityRules\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"description\": \"Deny all inbound traffic\",\n                    \"protocol\": \"*\",\n                    \"sourcePortRange\": \"*\",\n                    \"destinationPortRange\": \"*\",\n                    \"sourceAddressPrefix\": \"*\",\n                    \"destinationAddressPrefix\": \"*\",\n                    \"access\": \"Deny\",\n                    \"priority\": 65500,\n                    \"direction\": \"Inbound\",\n                    \"sourcePortRanges\": [],\n                    \"destinationPortRanges\": [],\n                    \"sourceAddressPrefixes\": [],\n                    \"destinationAddressPrefixes\": []\n                }\n            },\n            {\n                \"name\": \"AllowVnetOutBound\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg/defaultSecurityRules/AllowVnetOutBound\",\n                \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\",\n                \"type\": \"Microsoft.Network/networkSecurityGroups/defaultSecurityRules\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"description\": \"Allow outbound traffic from all VMs to all VMs in VNET\",\n                    \"protocol\": \"*\",\n                    \"sourcePortRange\": \"*\",\n                    \"destinationPortRange\": \"*\",\n                    \"sourceAddressPrefix\": \"VirtualNetwork\",\n                    \"destinationAddressPrefix\": \"VirtualNetwork\",\n                    \"access\": \"Allow\",\n                    \"priority\": 65000,\n                    \"direction\": \"Outbound\",\n                    \"sourcePortRanges\": [],\n                    \"destinationPortRanges\": [],\n                    \"sourceAddressPrefixes\": [],\n                    \"destinationAddressPrefixes\": []\n                }\n            },\n            {\n                \"name\": \"AllowInternetOutBound\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg/defaultSecurityRules/AllowInternetOutBound\",\n                \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\",\n                \"type\": \"Microsoft.Network/networkSecurityGroups/defaultSecurityRules\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"description\": \"Allow outbound traffic from all VMs to Internet\",\n                    \"protocol\": \"*\",\n                    \"sourcePortRange\": \"*\",\n                    \"destinationPortRange\": \"*\",\n                    \"sourceAddressPrefix\": \"*\",\n                    \"destinationAddressPrefix\": \"Internet\",\n                    \"access\": \"Allow\",\n                    \"priority\": 65001,\n                    \"direction\": \"Outbound\",\n                    \"sourcePortRanges\": [],\n                    \"destinationPortRanges\": [],\n                    \"sourceAddressPrefixes\": [],\n                    \"destinationAddressPrefixes\": []\n                }\n            },\n            {\n                \"name\": \"DenyAllOutBound\",\n                \"id\": \"/subscriptions/4ae8fd93-d084-481f-ba6e-370b7d4d8d0d/resourceGroups/NNUHFT-SDE-Networking/providers/Microsoft.Network/networkSecurityGroups/NNUHFT-SDE-nsg/defaultSecurityRules/DenyAllOutBound\",\n                \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\",\n                \"type\": \"Microsoft.Network/networkSecurityGroups/defaultSecurityRules\",\n                \"properties\": {\n                    \"provisioningState\": \"Succeeded\",\n                    \"description\": \"Deny all outbound traffic\",\n                    \"protocol\": \"*\",\n                    \"sourcePortRange\": \"*\",\n                    \"destinationPortRange\": \"*\",\n                    \"sourceAddressPrefix\": \"*\",\n                    \"destinationAddressPrefix\": \"*\",\n                    \"access\": \"Deny\",\n                    \"priority\": 65500,\n                    \"direction\": \"Outbound\",\n                    \"sourcePortRanges\": [],\n                    \"destinationPortRanges\": [],\n                    \"sourceAddressPrefixes\": [],\n                    \"destinationAddressPrefixes\": []\n                }\n            }\n        ]\n    },\n    \"etag\": \"W/\\\"71e18f50-f2f7-475f-9ba7-1d751a9229db\\\"\"\n}","language":"json","time":"5 days ago","created":"2025-11-19T14:14:34.887Z","annotations":[],"updated":"2025-11-19T15:11:18.305Z"}],"gptContexts":[],"gptFolderNames":[],"enrichedCode":{}}