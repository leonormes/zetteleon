---
aliases: []
confidence: 
created: 2025-08-26T09:26:56Z
epistemic: 
last_reviewed: 
modified: 2025-10-30T10:27:47Z
purpose: 
review_interval: 
see_also: []
source_of_truth: []
status: 
tags: [information]
title: The Conflict Between Semantic and Shannon Information
type:
uid: 
updated: 
version:
---

ðŸ†š There is a core conflict between the intuitive definition of information and the technical definition from [[Shannon's Information Theory - Information as Uncertainty]].

| Intuitive / Semantic View ([[Information as Perceivable Pattern]]) | Shannon's Mathematical View                                                 |
| ------------------------------------------------------------------ | --------------------------------------------------------------------------- |
| Information requires **pattern**, rules, and predictability.       | Predictability **reduces** information content (entropy).                   |
| Pure chaos or random noise is the **absence** of information.      | Pure random noise has the **maximum** information content.                  |
| A sequence like "ababab..." is highly informative.                 | A sequence like "ababab..." is highly predictable, thus low in information. |

This conflict arises because Shannon's theory deliberately ignores *meaning* (semantics) to focus on the statistical properties of signals. What we often mean by "information" in daily life is **meaningful signal**, not just raw data.

- **Links**: [[Information as Perceivable Pattern]], [[Shannon's Information Theory - Information as Uncertainty]], [[Kolmogorov Complexity - Information as Compressibility]], [[Three Perspectives on Information (Map of Content)]]
